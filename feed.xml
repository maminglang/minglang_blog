<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom"><id>https://github.com/maminglang/minglang_blog</id><title>RSS feed of maminglang's minglang_blog</title><updated>2022-12-15T02:03:41.518619+00:00</updated><author><name>maminglang</name><email>1622695094@qq.com</email></author><link href="https://github.com/maminglang/minglang_blog"/><link href="https://raw.githubusercontent.com/maminglang/minglang_blog/master/feed.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator><entry><id>https://github.com/maminglang/minglang_blog/issues/34</id><title>哈希表</title><updated>2022-12-15T02:03:41.753390+00:00</updated><content type="html"><![CDATA[<p>在Java中，哈希表常用的数据结构就是Map和Set，我们通过几个算法题目加深对这类数据结构的应用。</p>
<blockquote>
<p><a href="https://leetcode.cn/problems/two-sum/">1. 两数之和</a>
给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target  的那 两个 整数，并返回它们的数组下标。
你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。
你可以按任意顺序返回答案。</p>
</blockquote>
<p>示例 1：</p>
<pre><code>输入：nums = [2,7,11,15], target = 9
输出：[0,1]
解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。
</code></pre>
<p>示例 2：</p>
<pre><code>输入：nums = [3,2,4], target = 6
输出：[1,2]
</code></pre>
<p>示例 3：</p>
<pre><code>输入：nums = [3,3], target = 6
输出：[0,1]

</code></pre>
<p>思路：</p>
<ul>
<li>暴力法，直接两层循环，计算和是否等于target</li>
</ul>
<pre><code>public int[] twoSum(int[] nums, int target) {
        for(int i = 0; i&lt; nums.length;i++){
            for(int j = i+1;j &lt; nums.length;j++){
                if(nums[i] + nums[j] == target){
                    return new int[]{i,j};
                }
            }
        }
        return new int[]{};

    }
</code></pre>
<ul>
<li>
<p>使用哈希表，可以将寻找 <code>target - x </code>的时间复杂度降低到从 <strong>O(N)</strong> 降低到 <strong>O(1)</strong>。</p>
<pre><code> 这样我们创建一个哈希表，对于每一个` x`，我们首先查询哈希表中是否存在 `target - x`，然后将 `x` 插入到哈希表中，即可保 
</code></pre>
<p>证不会让<code> x</code> 和自己匹配</p>
</li>
</ul>
<pre><code>public int[] twoSum(int[] nums, int target) {
        Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;();
        for(int i = 0;i &lt; nums.length;i++){
            int res = target - nums[i];
            if(map.containsKey(res)){
                return new int[]{i,map.get(res)};
            }else{
                map.put(nums[i],i);
            }
        }
        return new int[]{};

    }
</code></pre>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/34" rel="alternate"/><category term="算法"/><published>2022-12-15T01:50:55+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/33</id><title>二叉树</title><updated>2022-12-15T02:03:41.844036+00:00</updated><content type="html"><![CDATA[<ul>
<li>二叉树的概念</li>
<li>满二叉树</li>
<li>完全二叉树</li>
<li>自平衡二叉树</li>
<li>红黑树</li>
</ul>
<h3>二叉树的村塾</h3>
<h3>二叉树䣌遍历</h3>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/33" rel="alternate"/><category term="算法"/><published>2022-12-08T07:24:16+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/32</id><title>IO模型</title><updated>2022-12-15T02:03:41.920840+00:00</updated><content type="html"><![CDATA[<h3>I/O模型</h3>
<p>I/O模型简单理解就是：采用什么样的通道进行数据的发送和接受，这很大程度上决定了程序的性能。
Java支持的3中网络编程模型I/O模式主要分为以下三种：<strong>BIO(同步并阻塞)</strong>、<strong>NIO（同步非阻塞</strong>、<strong>AIO（异步非阻塞）</strong></p>
<h4>阻塞与非阻塞</h4>
<p>这主要是指访问I/O的线程时候会阻塞，线程访问资源，资源时候会处于就绪状态</p>
<h4>同步与异步</h4>
<p>这指的是访问资源的一种机制，也就是数据的请求方式</p>
<h3>Java中的网络编程模型I/O模式</h3>
<h4>BIO</h4>
<p>bio就是传统的socket编程，服务器端的实现模式为一个连接一个线程，也就是说客户端有连接请求服务器端就需要启动一个线程进行处理。如果这个连接不做任何事情，则会造成不必要的线程开销，可以通过线程池机制实现多个客户端连接服务器改善性能。
<img src="https://user-images.githubusercontent.com/22972346/201517118-52dd38aa-bcc2-4253-9f03-8456d0e0b114.png" alt="image" /></p>
<h5>代码demo</h5>
<ul>
<li>服务器端</li>
</ul>
<pre><code>public class ServerDemo {
    public static void main(String[] args) throws Exception {
        ExecutorService executorService = Executors.newCachedThreadPool();
        ServerSocket serverSocket = new ServerSocket(9999);

        System.out.println(&quot;服务器已经启动&quot;);

        while (true) {
            final Socket socket = serverSocket.accept();
            System.out.println(&quot;有客户端连接&quot;);
            executorService.execute(new Runnable() {
                public void run() {
                    handle(socket);
                }
            });
        }
    }

    private static void handle(Socket socket) {
        try {
            System.out.println(&quot;线程ID: &quot; + Thread.currentThread().getId() + &quot;  线程名称： &quot; + Thread.currentThread().getName());
            InputStream inputStream = socket.getInputStream();
            byte[] bytes = new byte[1024];
            int read = inputStream.read(bytes);
            System.out.println(&quot;客户端输入内容为: &quot; + new String(bytes, 0, read).trim());
            OutputStream outputStream = socket.getOutputStream();
            OutputStream os = socket.getOutputStream();
            System.out.println(&quot;请输入：&quot;);
            Scanner scanner = new Scanner(System.in);
            String msg = scanner.nextLine();
            outputStream.write(msg.getBytes());

        } catch (Exception e) {

        }
    }
}
</code></pre>
<ul>
<li>客户端</li>
</ul>
<pre><code>public class ClientDemo {
    public static void main(String[] args) throws Exception {
        while(true){
            Socket socket = new Socket(&quot;127.0.0.1&quot;, 9999);
            OutputStream os = socket.getOutputStream();
            System.out.println(&quot;请输入：&quot;);
            Scanner scanner = new Scanner(System.in);
            String msg = scanner.nextLine();
            os.write(msg.getBytes());
            InputStream inputStream = socket.getInputStream();
            byte[] bytes = new byte[1024];
            int read = inputStream.read(bytes);
            System.out.println(&quot;老板说：&quot; + new String(bytes,0,read).trim());

        }
    }
}
</code></pre>
<h4>NIO（同步非阻塞）</h4>
<p>同步非阻塞，服务器实现模式为一个线程处理多个连接，即客户端发动的请求搜会注册到<strong>多路复用器</strong>上，多路复用器轮询到有连接I/O就进行处理
<img src="https://user-images.githubusercontent.com/22972346/201517322-c4fcd4af-ffc6-4a65-afef-9bcfd2857c61.png" alt="image" /></p>
<h3>NIO使用</h3>
<p>Java NIO 全称java non-blocking IO ，是指 JDK 提供的新 API。从 JDK1.4 开始，Java 提供了一系列改进的输入/输出的新特性，被统称为 NIO(即 New IO)，是同步非阻塞的. </p>
<ul>
<li>NIO 有<strong>三大核心部分</strong>：<strong>Channel(通道)，Buffer(缓冲区), Selector(选择器)</strong></li>
<li>
<ol start="2">
<li><strong>NIO是 面向缓冲区编程的</strong>。数据读取到一个缓冲区中，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞式的高伸缩性网络</li>
</ol>
</li>
<li>
<ol start="3">
<li>Java NIO 的非阻塞模式，使一个线程从某通道发送请求或者读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入， 这个线程同时可以去做别的事情。通俗理解：NIO 是可以做到
用一个线程来处理多个操作的。假设有 10000 个请求过来,根据实际情况，可以分配50 或者 100 个线程来处理。不像之前的阻塞 IO 那样，非得分配 10000 个</li>
</ol>
</li>
</ul>
<h4>三大组件</h4>
<p>三大组件之间的关系：</p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/32" rel="alternate"/><category term="Nio和Netty学习"/><published>2022-12-08T07:23:13+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/31</id><title>BlockQueue</title><updated>2022-12-15T02:03:42.003179+00:00</updated><content type="html"><![CDATA[<pre><code>public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; {
//添加元素
boolean add(E e);
boolean offer(E e);
void put(E e) throws InterruptedException;
//删除元素
boolean remove(Object o);
//获取元素
 E take() throws InterruptedException;
E poll(long timeout, TimeUnit unit)
        throws InterruptedException;
}
</code></pre>
<h3>ArrayBlockingQueue</h3>
<p><strong>基于数组实现的环形队列</strong>
首先来看构造函数：</p>
<pre><code>public ArrayBlockingQueue(int capacity) {
        this(capacity, false);
    }
public ArrayBlockingQueue(int capacity, boolean fair) {
        if (capacity &lt;= 0)
            throw new IllegalArgumentException();
        this.items = new Object[capacity];
        lock = new ReentrantLock(fair);
        notEmpty = lock.newCondition();
        notFull =  lock.newCondition();
    }

 public ArrayBlockingQueue(int capacity, boolean fair,
                              Collection&lt;? extends E&gt; c){}
</code></pre>
<p>在构造函数中，会要求传入数组的容量。</p>
<h4>属性</h4>
<pre><code>  /** The queued items */
    final Object[] items;

    /** items index for next take, poll, peek or remove */
    int takeIndex;

    /** items index for next put, offer, or add */
    int putIndex;

    /** Number of elements in the queue */
    int count;

    /*
     * Concurrency control uses the classic two-condition algorithm
     * found in any textbook.
     */

    /** Main lock guarding all access */
    final ReentrantLock lock;

    /** Condition for waiting takes */
    private final Condition notEmpty;

    /** Condition for waiting puts */
    private final Condition notFull;

    /**
     * Shared state for currently active iterators, or null if there
     * are known not to be any.  Allows queue operations to update
     * iterator state.
     */
    transient Itrs itrs;
</code></pre>
<p>属性倒是很简单，就是一个Object数组，头指针和尾指针，队列中元素的个数，一个可重入锁和两个condition条件用于实现生产-消费者模式</p>
<h6>put方法</h6>
<pre><code> public void put(E e) throws InterruptedException {
        Objects.requireNonNull(e);
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();//可中断的lock
        try {
            while (count == items.length)
                notFull.await();//队列已经满了，阻塞生产者线程
            enqueue(e);
        } finally {
            lock.unlock();
        }
    }
</code></pre>
<pre><code>private void enqueue(E e) {
        final Object[] items = this.items;
        items[putIndex] = e;
        if (++putIndex == items.length) putIndex = 0;//此处为实现环形队列的条件
        count++;
        notEmpty.signal();
    }
</code></pre>
<h4>LinkedBlockingQueue</h4>
<p>基于单向链表的阻塞队列，因为对头和队尾是两个指针进行分开操作的，所以用了两个锁和两个条件，同时有一个AtomicInteger的原子变量来记录count数</p>
<pre><code> /** The capacity bound, or Integer.MAX_VALUE if none */
    private final int capacity;

    /** Current number of elements */
    private final AtomicInteger count = new AtomicInteger();

    /**
    *单向链表的头部
     * Head of linked list.
     * Invariant: head.item == null
     */
    transient Node&lt;E&gt; head;

    /**
     * 单向链表的尾部
     * Tail of linked list.
     * Invariant: last.next == null
     */
    private transient Node&lt;E&gt; last;

    /** Lock held by take, poll, etc */
    private final ReentrantLock takeLock = new ReentrantLock();

    /** Wait queue for waiting takes */
    private final Condition notEmpty = takeLock.newCondition();

    /** Lock held by put, offer, etc */
    private final ReentrantLock putLock = new ReentrantLock();

    /** Wait queue for waiting puts */
    private final Condition notFull = putLock.newCondition()
</code></pre>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/31" rel="alternate"/><category term="Java源码"/><published>2022-12-06T13:17:12+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/30</id><title>多线程交替打印数字</title><updated>2022-12-15T02:03:42.075950+00:00</updated><content type="html"><![CDATA[<p>使用ReetranLock和condition实现</p>
<pre><code>public class Test {

    static int count = 0;

    public static void main(String[] args) {

        ReentrantLock lock = new ReentrantLock();
        Condition conditionA = lock.newCondition();
        Condition conditionB = lock.newCondition();
        Condition conditionC = lock.newCondition();
        new Thread(() -&gt; {
            print(lock, conditionA, conditionB, 0);
        }, &quot;1&quot;).start();

        new Thread(() -&gt; {
            print(lock, conditionB, conditionC, 1);

        }, &quot;2&quot;).start();

        new Thread(() -&gt; {
            print(lock, conditionC, conditionA, 2);

        }, &quot;3&quot;).start();
    }

    static void print(ReentrantLock lock, Condition currentCondition, Condition nextCondition, int targetNum) {
        try {
            // 加锁,进入并发控制内部
            lock.lock();
            while (true) {
                while (count % 3 != targetNum) {
                   //不满足条件，阻塞当前线程
                    currentCondition.await();
                }
                System.out.print(Thread.currentThread().getName());
                // 将阻塞在 conditionB 的线程唤醒
                nextCondition.signal();
                count++;
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
    }

}

</code></pre>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/30" rel="alternate"/><category term="多线程学习"/><published>2022-12-05T06:42:14+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/29</id><title>集合相关源码阅读</title><updated>2022-12-15T02:03:42.161632+00:00</updated><content type="html"><![CDATA[<h3>ArrayList</h3>
<h3>HashMap</h3>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/29" rel="alternate"/><category term="Java源码"/><published>2022-12-01T00:58:21+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/28</id><title>DMQ相关</title><updated>2022-12-15T02:03:42.241364+00:00</updated><content type="html"><![CDATA[<h3>Apache Kafka架构</h3>
<p><img src="https://user-images.githubusercontent.com/22972346/204415347-8699fd43-627d-4b5c-a897-9bdb8895118d.png" alt="image" />
如图所示，Kafka的架构中包括Producer、Kafka-Broker、ZooKeeper、Consumer。</p>
<ul>
<li>Producer</li>
</ul>
<p>通过push模式向Kafka Broker发送消息。</p>
<ul>
<li>Kafka Broker</li>
</ul>
<p>用于存储消息的服务器。至少需要3个节点</p>
<ul>
<li>Zookeeper</li>
</ul>
<p>管理集群的配置、选举leader分区，并且在消费者Group发生变化时，进行负载均衡</p>
<ul>
<li>Consumer</li>
</ul>
<p>通过pull模式从Kafka-Broker订阅并消费消息。</p>
<p>此外：</p>
<p>Group和Topic的对应关系是<strong>N : N</strong>，即一个Group可以同时订阅多个Topic，一个Topic也可以被多个Group同时订阅。</p>
<p>虽然一个Topic可以被多个Group同时订阅，但该Topic的消息只能被同一个Group内的任意一个Consumer消费。</p>
<h3>Apache Pulsar系统架构</h3>
<p><img src="https://user-images.githubusercontent.com/22972346/204415544-e55d8198-ee3b-463d-b6b2-e6f1f4db28d6.png" alt="image" />
如图所示，Pulsar的架构中包括Producer、Pulsar-Broker、ZooKeeper、Bookie、Consumer。</p>
<p>与Kafka的主要区别在于Pulsar系统设计上实现了计算、存储分离，Pulsar Broker节点负责客户端请求处理，Bookkeeper负责数据存储</p>
<ul>
<li>Producer</li>
</ul>
<p>通过push模式向PulsarBroker发送消息。</p>
<ul>
<li>PulsarBroker</li>
</ul>
<p>用于客户端请求处理，节点无状态，不保存数据</p>
<ul>
<li>Zookeeper</li>
</ul>
<p>管理集群的配置、选举leader、Bookie、broker的元数据存储等，Pulsar整个系统对ZK的依赖程度远高于Kafka</p>
<ul>
<li>Bookie</li>
</ul>
<p>Apache Bookkeeper开源软件，分布式数据存储，用于存储pulsar系统的消息内容</p>
<ul>
<li>Consumer</li>
</ul>
<p>通过pull模式从Pulsar-Broker订阅并消费消息。</p>
<h3>DMQ系统架构1.0（单集群单AZ，多云架构）</h3>
<p><img src="https://user-images.githubusercontent.com/22972346/204415890-93da4fb8-0e33-4a27-8a72-7a2bfd1f698e.png" alt="image" />
如图所示，DMQ 1.0的架构，基于Kafka，增加了Admin控制台、注册中心模块。</p>
<p>​ 此外，目前的双云架构，AZ1与AZ2的集群，相互独立，数据默认情况下只写入AZ1，AZ1与AZ2之间不做数据同步</p>
<ul>
<li>Registry</li>
</ul>
<p>注册中心模块，目前主要有Apache Zookeeper与NUWA Cloudmap</p>
<p>Producer与Consumer初始化时，需要访问注册中心模块，通过Topic查询对应的集群地址、主备策略信息等，然后再与对应的集群建立连接</p>
<p>URL 示例：mq://10.33.45.170:9092/up.delRealName?application=kafka&amp;bootstrap.servers=10.33.45.170:9092,10.33.45.174:9092,10.33.45.85:9092&amp;dubbo=2.5.4-SNAPSHOT&amp;dynamic=false&amp;interface=up.delRealName&amp;methods=subscribe,unSubscribe,send&amp;mq.type=kafka&amp;zookeeper.connect=10.33.45.170:2181,10.33.45.174:2181,10.33.45.85:2181&amp;mq.dual.backup=true</p>
<pre><code>  ​up.delRealName：Topic名称

  ​bootstrap.servers：Kafka地址

  ​zookeeper.connect：Zookeeper地址

  ​mq.dual.backup：主备信息
</code></pre>
<ul>
<li>
<p>DMQ Admin Console</p>
<p>1、集群的部署</p>
<p>2、Topic的增删改查，路由信息同步Registry等</p>
<p>3、授权管理等</p>
</li>
</ul>
<h3>DMQ系统架构3.0（单集群多AZ、多云架构）</h3>
<p>Kafka的设计模式上，存在一些问题：</p>
<pre><code>1.broker扩容后，需要手动迁移数据，易用性上存在问题
2.ISR的设计模式，在高一致性场景，ACK=ALL的情况下，容易存在时延波动
3.分区数上限问题。分区越多，磁盘随机写，性能影响
</code></pre>
<p>刚好，Apache Pulsar可以解决上面的问题，且可以兼容Kafka的API，客户端可以直接使用Kafka的Client，无需升级SDK
<img src="https://user-images.githubusercontent.com/22972346/204416098-de847678-719e-4a16-ab2f-c222955a5104.png" alt="image" /></p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/28" rel="alternate"/><category term="Kafka"/><published>2022-11-29T08:34:56+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/27</id><title>高性能IO模型</title><updated>2022-12-15T02:03:42.330860+00:00</updated><content type="html"><![CDATA[<p>Redis是单线程，主要是指<strong>Redis的网络IO和键值对读写是由一个线程来完成的，这也是Redis对外提供键值存储服务的主要流程</strong>。但是Redis的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。</p>
<h4>Redis的单线程设计机制以及多路复用机制</h4>
<h5>为什么采用单线程设计</h5>
<ul>
<li>多线程编程模式面临的共享资源的并发访问控制问题</li>
<li>引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性</li>
</ul>
<h5>单线程为什么这么快</h5>
<ul>
<li>大部分操作是在内存上完成的</li>
<li>高效的数据结构</li>
<li>多路复用机制
Redis单线程处理IO请求性能瓶颈主要包括2个方面： 1、任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种： a、操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时； b、使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据； c、大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长； d、淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长； e、AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能； f、主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久； 2、并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。 针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。 针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/27" rel="alternate"/><category term="Redis"/><published>2022-11-22T06:16:05+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/25</id><title>OAuth 2.0</title><updated>2022-12-15T02:03:42.411505+00:00</updated><content type="html"><![CDATA[<h3>简单解释</h3>
<p>OAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用</p>
<h4>授权方式</h4>
<ul>
<li>授权码（authorization-code）
授权码（authorization code）方式，指的是第三方应用先申请一个授权码，然后再用该码获取令牌。</li>
<li>隐藏式（implicit）</li>
<li>密码式（password）：</li>
<li>客户端凭证（client credentials）</li>
</ul>
<h3>代码Demo</h3>
<p>基于Spring Security Oauth2的SSO单点登录+JWT权限控制实践
多模块（Multi-Module）项目搭建
三个应用通过一个多模块的 Maven项目进行组织，其中项目父 pom中需要加入相关依赖如下：</p>
<pre><code>&lt;dependencies&gt;

	&lt;dependency&gt;
		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
		&lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
		&lt;version&gt;2.0.8.RELEASE&lt;/version&gt;
		&lt;type&gt;pom&lt;/type&gt;
		&lt;scope&gt;import&lt;/scope&gt;
	&lt;/dependency&gt;

	&lt;dependency&gt;
		&lt;groupId&gt;io.spring.platform&lt;/groupId&gt;
		&lt;artifactId&gt;platform-bom&lt;/artifactId&gt;
		&lt;version&gt;Cairo-RELEASE&lt;/version&gt;
		&lt;type&gt;pom&lt;/type&gt;
		&lt;scope&gt;import&lt;/scope&gt;
	&lt;/dependency&gt;

	&lt;dependency&gt;
		&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
		&lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
		&lt;version&gt;Finchley.SR2&lt;/version&gt;
		&lt;type&gt;pom&lt;/type&gt;
		&lt;scope&gt;import&lt;/scope&gt;
	&lt;/dependency&gt;

&lt;/dependencies&gt;
</code></pre>
<p>项目结构如下：</p>
<p><img src="https://user-images.githubusercontent.com/22972346/201466967-50864ed2-2a0e-41c3-ba01-30d03eec86ba.png" alt="image" /></p>
<h4>授权认证中心搭建</h4>
<p>授权认证中心本质就是一个 Spring Boot应用，因此需要完成几个大步骤：</p>
<ul>
<li>pom中添加依赖</li>
</ul>
<pre><code>&lt;dependencies&gt;
	&lt;dependency&gt;
		&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
		&lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;
	&lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<ul>
<li>项目 yml配置文件：</li>
</ul>
<pre><code>server:
  port: 8085
  servlet:
    context-path: /uac
</code></pre>
<p>即让授权中心服务启动在本地的 8085端口之上</p>
<ul>
<li>创建一个带指定权限的模拟用户</li>
</ul>
<pre><code>@Component
public class SheepUserDetailsService implements UserDetailsService {

    @Autowired
    private PasswordEncoder passwordEncoder;

    @Override
    public UserDetails loadUserByUsername(String s) throws UsernameNotFoundException {

        if( !&quot;codesheep&quot;.equals(s) )
            throw new UsernameNotFoundException(&quot;用户&quot; + s + &quot;不存在&quot; );

        return new User( s, passwordEncoder.encode(&quot;123456&quot;), AuthorityUtils.commaSeparatedStringToAuthorityList(&quot;ROLE_NORMAL,ROLE_MEDIUM&quot;));
    }
}
</code></pre>
<p>这里创建了一个用户名为codesheep，密码 123456的模拟用户，并且赋予了 普通权限（ROLE_NORMAL）和 中等权限（ROLE_MEDIUM）</p>
<ul>
<li>认证服务器配置 AuthorizationServerConfig</li>
</ul>
<pre><code>@Configuration
@EnableAuthorizationServer
public class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter {

    @Override
    public void configure(ClientDetailsServiceConfigurer clients) throws Exception {

        // 定义了两个客户端应用的通行证
        clients.inMemory()
                .withClient(&quot;sheep1&quot;)
                .secret(new BCryptPasswordEncoder().encode(&quot;123456&quot;))
                .authorizedGrantTypes(&quot;authorization_code&quot;, &quot;refresh_token&quot;)
                .scopes(&quot;all&quot;)
                .autoApprove(false)
                .and()
                .withClient(&quot;sheep2&quot;)
                .secret(new BCryptPasswordEncoder().encode(&quot;123456&quot;))
                .authorizedGrantTypes(&quot;authorization_code&quot;, &quot;refresh_token&quot;)
                .scopes(&quot;all&quot;)
                .autoApprove(false);
    }

    @Override
    public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception {

        endpoints.tokenStore(jwtTokenStore()).accessTokenConverter(jwtAccessTokenConverter());
        DefaultTokenServices tokenServices = (DefaultTokenServices) endpoints.getDefaultAuthorizationServerTokenServices();
        tokenServices.setTokenStore(endpoints.getTokenStore());
        tokenServices.setSupportRefreshToken(true);
        tokenServices.setClientDetailsService(endpoints.getClientDetailsService());
        tokenServices.setTokenEnhancer(endpoints.getTokenEnhancer());
        tokenServices.setAccessTokenValiditySeconds((int) TimeUnit.DAYS.toSeconds(1)); // 一天有效期
        endpoints.tokenServices(tokenServices);
    }

    @Override
    public void configure(AuthorizationServerSecurityConfigurer security) throws Exception {
        security.tokenKeyAccess(&quot;isAuthenticated()&quot;);
    }

    @Bean
    public TokenStore jwtTokenStore() {
        return new JwtTokenStore(jwtAccessTokenConverter());
    }

    @Bean
    public JwtAccessTokenConverter jwtAccessTokenConverter(){
        JwtAccessTokenConverter converter = new JwtAccessTokenConverter();
        converter.setSigningKey(&quot;testKey&quot;);
        return converter;
    }
}
</code></pre>
<p>这里做的最重要的两件事：一是 定义了两个客户端应用的通行证（sheep1和sheep2）；二是 配置 token的具体实现方式为 JWT Token。</p>
<ul>
<li>Spring Security安全配置 SpringSecurityConfig</li>
</ul>
<pre><code>@Configuration
public class SpringSecurityConfig extends WebSecurityConfigurerAdapter {

    @Override
    @Bean
    public AuthenticationManager authenticationManager() throws Exception {
        return super.authenticationManager();
    }

    @Autowired
    private UserDetailsService userDetailsService;

    @Bean
    public PasswordEncoder passwordEncoder() {
        return new BCryptPasswordEncoder();
    }

    @Bean
    public DaoAuthenticationProvider authenticationProvider() {
        DaoAuthenticationProvider authenticationProvider = new DaoAuthenticationProvider();
        authenticationProvider.setUserDetailsService(userDetailsService);
        authenticationProvider.setPasswordEncoder(passwordEncoder());
        authenticationProvider.setHideUserNotFoundExceptions(false);
        return authenticationProvider;
    }
    
    @Override
    protected void configure(HttpSecurity http) throws Exception {

        http
                .requestMatchers().antMatchers(&quot;/oauth/**&quot;,&quot;/login/**&quot;,&quot;/logout/**&quot;)
                .and()
                .authorizeRequests()
                .antMatchers(&quot;/oauth/**&quot;).authenticated()
                .and()
                .formLogin().permitAll();
    }

    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth.authenticationProvider(authenticationProvider());
    }

}
</code></pre>
<h4>客户端应用创建和配置</h4>
<p>本文创建两个客户端应用：codesheep-client1 和codesheep-client2，由于两者类似，因此只以其一为例进行讲解</p>
<ul>
<li>SSO客户端应用配置类 ClientWebsecurityConfigurer</li>
</ul>
<pre><code>@Configuration
@EnableWebSecurity
@EnableGlobalMethodSecurity(prePostEnabled = true)
@EnableOAuth2Sso
public class ClientWebsecurityConfigurer extends WebSecurityConfigurerAdapter {

    @Override
    public void configure(HttpSecurity http) throws Exception {
        http.antMatcher(&quot;/**&quot;).authorizeRequests()
                .anyRequest().authenticated();
    }
}
</code></pre>
<p>复杂的东西都交给注解了！</p>
<ul>
<li>application.yml配置</li>
</ul>
<pre><code>auth-server: http://localhost:8085/uac
server:
  port: 8086

security:
  oauth2:
    client:
      client-id: sheep1
      client-secret: 123456
      user-authorization-uri: ${auth-server}/oauth/authorize
      access-token-uri: ${auth-server}/oauth/token
    resource:
      jwt:
        key-uri: ${auth-server}/oauth/token_key
</code></pre>
<p>这里几项配置都非常重要，都是需要和前面搭建的授权中心进行通信的</p>
<ul>
<li>创建测试控制器 TestController</li>
</ul>
<pre><code>@RestController
public class TestController {

   @GetMapping(&quot;/normal&quot;)
   @PreAuthorize(&quot;hasAuthority(&#x27;ROLE_NORMAL&#x27;)&quot;)
   public String normal( ) {
       return &quot;normal permission test success !!!&quot;;
   }

   @GetMapping(&quot;/medium&quot;)
   @PreAuthorize(&quot;hasAuthority(&#x27;ROLE_MEDIUM&#x27;)&quot;)
   public String medium() {
       return &quot;medium permission test success !!!&quot;;
   }

   @GetMapping(&quot;/admin&quot;)
   @PreAuthorize(&quot;hasAuthority(&#x27;ROLE_ADMIN&#x27;)&quot;)
   public String admin() {
       return &quot;admin permission test success !!!&quot;;
   }
}
</code></pre>
<p>此测试控制器包含三个接口，分别需要三种权限（ROLE_NORMAL、ROLE_MEDIUM、ROLE_ADMIN），待会后文会一一测试看效果</p>
<p>实验验证
启动授权认证中心 codesheep-server（启动于本地8085端口）
启动客户端应用 codesheep-client1 （启动于本地8086端口）
启动客户端应用 codesheep-client2 （启动于本地8087端口）
首先用浏览器访问客户端1 (codesheep-client1) 的测试接口：localhost:8086/normal，由于此时并没有过用户登录认证，因此会自动跳转到授权中心的登录认证页面：http://localhost:8085/uac/login：
<img src="https://user-images.githubusercontent.com/22972346/201467085-5f8a6b96-1bc0-4b34-9d08-882861cf3123.png" alt="image" /></p>
<p>自动跳转到授权中心统一登录页面</p>
<p>输入用户名 codesheep，密码 123456，即可登录认证，并进入授权页面：</p>
<p>同意授权后，会自动返回之前客户端的测试接口：
<img src="https://user-images.githubusercontent.com/22972346/201467106-c93db348-dc5c-414d-8bde-acbc1509dec9.png" alt="image" /></p>
<p>自动返回客户端接口并调用成功</p>
<p>此时我们再继续访问客户端1 (codesheep-client1) 的测试接口：localhost:8086/medium，发现已经直接可以调用而无需认证了：</p>
<p>由于 localhost:8086/normal 和 localhost:8086/medium要求的接口权限，用户codesheep均具备，所以能顺利访问，接下来再访问一下更高权限的接口：localhost:8086/admin：</p>
<p>无权限访问</p>
<p>好了，访问客户端1 (codesheep-client1) 的测试接口到此为止，接下来访问外挂的客户端2 (codesheep-client2) 的测试接口：localhost:8087/normal，会发现此时会自动跳到授权页：</p>
<p>由于用户已通过客户端1登录过_因此再访问客户端2即无需登录_而是直接跳到授权页</p>
<p>授权完成之后就可以顺利访问客户端2 (codesheep-client2) 的接口：</p>
<p>顺利访问客户端2的接口</p>
<p>这就验证了单点登录SSO的功能了！</p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/25" rel="alternate"/><category term="Oauth"/><published>2022-11-09T14:56:37+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/24</id><title>JWT学习</title><updated>2022-12-15T02:03:42.502131+00:00</updated><content type="html"><![CDATA[<p>JSON Web Token（缩写 JWT）是目前最流行的跨域认证解决方案，本文介绍它的原理和用法。</p>
<h3>一、跨域认证的问题</h3>
<p>互联网服务离不开用户认证。一般流程是下面这样。</p>
<blockquote>
<p>1、用户向服务器发送用户名和密码。
2、服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间等等。
3、服务器向用户返回一个 session_id，写入用户的 Cookie。
4、用户随后的每一次请求，都会通过 Cookie，将 session_id 传回服务器。
5、服务器收到 session_id，找到前期保存的数据，由此得知用户的身份。</p>
</blockquote>
<p>这种模式的问题在于，扩展性（scaling）不好。单机当然没有问题，如果是服务器集群，或者是跨域的服务导向架构，就要求 session 数据共享，每台服务器都能够读取 session。</p>
<p>举例来说，A 网站和 B 网站是同一家公司的关联服务。现在要求，用户只要在其中一个网站登录，再访问另一个网站就会自动登录，请问怎么实现？</p>
<p>一种解决方案是 session 数据持久化，写入数据库或别的持久层。各种服务收到请求后，都向持久层请求数据。这种方案的优点是架构清晰，缺点是工程量比较大。另外，持久层万一挂了，就会单点失败。</p>
<p>另一种方案是服务器索性不保存 session 数据了，所有数据都保存在客户端，每次请求都发回服务器。JWT 就是这种方案的一个代表。</p>
<h3>二、JWT 的原理</h3>
<p>JWT 的原理是，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样。</p>
<pre><code>{
  &quot;姓名&quot;: &quot;张三&quot;,
  &quot;角色&quot;: &quot;管理员&quot;,
  &quot;到期时间&quot;: &quot;2018年7月1日0点0分&quot;
</code></pre>
<p>以后，用户与服务端通信的时候，都要发回这个 JSON 对象。服务器完全只靠这个对象认定用户身份。为了防止用户篡改数据，服务器在生成这个对象的时候，会加上签名（详见后文）。</p>
<p>服务器就不保存任何 session 数据了，也就是说，服务器变成无状态了，从而比较容易实现扩展。</p>
<h3>三、JWT 的数据结构</h3>
<p>实际的 JWT 大概就像下面这样。</p>
<p><img src="https://user-images.githubusercontent.com/22972346/200469399-39cfc6af-1ec0-4bd2-9b4c-3964a8e4b8a2.png" alt="image" /></p>
<p>它是一个很长的字符串，中间用点（.）分隔成三个部分。注意，JWT 内部是没有换行的，这里只是为了便于展示，将它写成了几行。</p>
<p>JWT 的三个部分依次如下。</p>
<blockquote>
<ul>
<li>Header（头部）</li>
<li>Payload（负载）</li>
<li>Signature（签名）</li>
</ul>
</blockquote>
<p>写成一行，就是下面的样子。</p>
<blockquote>
<p>Header.Payload.Signature</p>
</blockquote>
<p>下面依次介绍这三个部分。</p>
<p>3.1 Header
Header 部分是一个 JSON 对象，描述 JWT 的元数据，通常是下面的样子。</p>
<p>{
&quot;alg&quot;: &quot;HS256&quot;,
&quot;typ&quot;: &quot;JWT&quot;
}
上面代码中，alg属性表示签名的算法（algorithm），默认是 HMAC SHA256（写成 HS256）；typ属性表示这个令牌（token）的类型（type），JWT 令牌统一写为JWT。</p>
<p>最后，将上面的 JSON 对象使用 Base64URL 算法（详见后文）转成字符串。</p>
<p>3.2 Payload
Payload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段，供选用。</p>
<p>iss (issuer)：签发人
exp (expiration time)：过期时间
sub (subject)：主题
aud (audience)：受众
nbf (Not Before)：生效时间
iat (Issued At)：签发时间
jti (JWT ID)：编号
除了官方字段，你还可以在这个部分定义私有字段，下面就是一个例子。</p>
<p>{
&quot;sub&quot;: &quot;1234567890&quot;,
&quot;name&quot;: &quot;John Doe&quot;,
&quot;admin&quot;: true
}
注意，JWT 默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。</p>
<p>这个 JSON 对象也要使用 Base64URL 算法转成字符串。</p>
<p>3.3 Signature
Signature 部分是对前两部分的签名，防止数据篡改。</p>
<p>首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。</p>
<p>HMACSHA256(
base64UrlEncode(header) + &quot;.&quot; +
base64UrlEncode(payload),
secret)
算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，每个部分之间用&quot;点&quot;（.）分隔，就可以返回给用户。</p>
<p>3.4 Base64URL
前面提到，Header 和 Payload 串型化的算法是 Base64URL。这个算法跟 Base64 算法基本类似，但有一些小的不同。</p>
<p>JWT 作为一个令牌（token），有些场合可能会放到 URL（比如 api.example.com/?token=xxx）。Base64 有三个字符+、/和=，在 URL 里面有特殊含义，所以要被替换掉：=被省略、+替换成-，/替换成_ 。这就是 Base64URL 算法。</p>
<p>四、JWT 的使用方式
客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。</p>
<p>此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息Authorization字段里面。</p>
<p>Authorization: Bearer <token>
另一种做法是，跨域的时候，JWT 就放在 POST 请求的数据体里面。</p>
<p>五、JWT 的几个特点
（1）JWT 默认是不加密，但也是可以加密的。生成原始 Token 以后，可以用密钥再加密一次。</p>
<p>（2）JWT 不加密的情况下，不能将秘密数据写入 JWT。</p>
<p>（3）JWT 不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数。</p>
<p>（4）JWT 的最大缺点是，由于服务器不保存 session 状态，因此无法在使用过程中废止某个 token，或者更改 token 的权限。也就是说，一旦 JWT 签发了，在到期之前就会始终有效，除非服务器部署额外的逻辑。</p>
<p>（5）JWT 本身包含了认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。为了减少盗用，JWT 的有效期应该设置得比较短。对于一些比较重要的权限，使用时应该再次对用户进行认证。</p>
<p>（6）为了减少盗用，JWT 不应该使用 HTTP 协议明码传输，要使用 HTTPS 协议传输。</p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/24" rel="alternate"/><category term="Oauth"/><published>2022-11-08T03:34:33+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/23</id><title>整数除法</title><updated>2022-12-15T02:03:42.601471+00:00</updated><content type="html"><![CDATA[<ul>
<li>题目描述：</li>
</ul>
<blockquote>
<p>题目：输入2个int型整数，它们进行除法计算并返回商，要求不得使用乘号'*'、除号'/'及求余符号'%'。当发生溢出时，返回最大的整数值。假设除数不为0。例如，输入15和2，输出15/2的结果，即7。</p>
</blockquote>
<p>首先，Java中的int类型的数值范围为<code>-2^31~2^31-1</code>，int型整数的除法只有一种情况会导致溢出，即（-2^31）/（-1）.</p>
<ul>
<li>Java中的int类型标识与补码相关知识
二进制数在内存中以补码的形式存储</li>
</ul>
<p>正数：原码、补码和反码都相同</p>
<p>负数：补码符号位不变，其它位是对应正数的原码取反加一。
因此，int类型的取值范围为：0x80000000 ~ 0x7fffffff</p>
<pre><code> public static int divide(int dividend, int divisor) {
       //如果是（-2^31）/（-1），则返回最大值，溢出处理
        if (dividend == 0x80000000 &amp;&amp; divisor == -1) {
            return Integer.MAX_VALUE;
        }
        int negative = 2;
        if (dividend &gt; 0) {
            negative --;
            dividend = -dividend;
        }
        if (divisor &gt; 0) {
            negative --;
            divisor = -divisor;
        }
       //如果将其都转化成正整数除法，也可能会溢出，比如-2^31/1，此时如果转化成正整数触发就会溢出，但是转成负整数
      //除法则不会存在这个问题
        int res = divideCore(dividend, divisor);
        return negative == 1 ? -res : res;

    }

    //为了避免溢出，使用的时负数的计算逻辑，返回值为正值
    private static int divideCore(int dividend, int divisor) {
        int result = 0;
        //被除数和除数都是负数
        while (dividend &lt;= divisor) {
            int value = divisor;
            int quotient = 1; //商
        //value &gt; 0xc0000000（-2^30），是为了保证负数不溢出
            while (value &gt; 0xc0000000 &amp;&amp; dividend &lt;= value + value) {
                quotient += quotient;
                value += value ;
            }
          //更新最大倍数的商的余数，其理解为 15/2，2的3倍为8，此时商为3，接下来计算（15-8）/2的商
            result += quotient;
            dividend -= value;


        }
        return result;
    }
</code></pre>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/23" rel="alternate"/><category term="算法"/><published>2022-10-31T06:46:37+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/22</id><title>ThreadLocal使用-上下文</title><updated>2022-12-15T02:03:42.676467+00:00</updated><content type="html"><![CDATA[<p>在代码中有个工具类 - <strong>ReqCtxUtil</strong> ，这个类中使用ThreadLocal来传递上下文，且在supplier执行完毕之后移除，防止ThreadLocal占用内存过大而导致oom</p>
<pre><code>

/**
 * 请求上下文工具类.
 */
public class ReqCtxUtil extends ComponentAware {
    private static ThreadLocal&lt;RequestContext&gt; currentReqCtx = new ThreadLocal&lt;&gt;();

    private ReqCtxUtil() {
    }

    /**
     * Set request context if target is aware.
     *
     * @param target target
     * @param reqCtx reqCtx
     */
    public static void setReqCtxIfAware(Object target, RequestContext reqCtx) {
        if (target instanceof IRequestContextAware) {
            ((IRequestContextAware) target).setRequestContext(reqCtx);
        }
    }

    /**
     * Need current request context. All code run within orchestration threads or other threads spawned by orchestration
     * could access RequestContext directly. You could use current RequestContext to pass temp variable between far-away
     * code, e.g:
     * &lt;p&gt;
     * Skill hierarchy code :
     * &lt;p&gt;
     * ReqCtxUtil.needCurrentCtx().putVar(VAR_DOMAIN_SCORE_DISTRIBUTION, scoreDistribution);
     * &lt;p&gt;
     * LambdaMART code :
     * &lt;p&gt;
     * scoreDistribution = ReqCtxUtil.needCurrentCtx().getVar(VAR_DOMAIN_SCORE_DISTRIBUTION);
     *
     * @return Current request context if exists or else RuntimeException will be thrown
     */
    public static RequestContext needCurrentReqCtx() {
        RequestContext result = getCurrentReqCtx();

        Assert.notNull(result,
            &quot;There is no request context in current thread. Only the code ran within the orchestration&quot;
                + &quot; threads or spawned by them could access the request context&quot;);

        return result;
    }

    /**
     * Get current request context.
     *
     * @return Current request context if exists or else null
     */
    public static RequestContext getCurrentReqCtx() {
        return currentReqCtx.get();
    }

    /**
     * 设置上下文
     *
     * @param reqCtx 上下文
     */
    public static void setCurrentReqCtx(RequestContext reqCtx) {
        currentReqCtx.set(reqCtx);
    }

    /**
     * 清空上下文
     */
    public static void removeCurrentReqCtx() {
        currentReqCtx.remove();
    }

    /**
     * Run within request context.
     *
     * @param &lt;T&gt; The type of result
     * @param reqCtx reqCtx
     * @param action action
     * @return &lt;T&gt; &lt;/T&gt;
     */
    public static &lt;T&gt; T runWithin(RequestContext reqCtx, Supplier&lt;T&gt; action) {
        currentReqCtx.set(reqCtx);
        try {
            return action.get();
        } finally {
            // 异步场景下，不移除上下文，防止在当前线程执行，导致上下文丢失 DTS2022091703340
            if (!getConfig().booleanOf(globalOf(&quot;hivoice.async.continuationOrchTask.enabled&quot;), false)) {
                currentReqCtx.remove();
            }
        }
    }

    /**
     * Run within request context.
     *
     * @param reqCtx reqCtx
     * @param runnable runnable
     */
    public static void runWithin(RequestContext reqCtx, Runnable runnable) {
        runWithin(reqCtx, () -&gt; {
            runnable.run();
            return StringUtils.EMPTY;
        });
    }

    /**
     * Equip with current request context : all methods will run within current request context if there has one.&lt;br/&gt;
     * 这个代理的方法有个原生的限制，就是所代理的类必须实现某个接口，可以考虑是用cglib来替换
     *
     * @param intf interface
     * @param target target
     * @param &lt;T&gt; T
     * @return &lt;T&gt; T A proxy which delegates all invocations to target within current request context &lt;/T&gt;
     */
    @SuppressWarnings(&quot;unchecked&quot;)
    public static &lt;T&gt; T equipWithCurrentReqCtx(Class&lt;T&gt; intf, T target) {
        RequestContext reqCtx = getCurrentReqCtx();

        return (T) Proxy.newProxyInstance(target.getClass().getClassLoader(), cls(intf), (proxy, method, args) -&gt; {
            return runWithin(reqCtx, () -&gt; {
                try {
                    return method.invoke(target, args);
                } catch (IllegalAccessException | IllegalArgumentException | InvocationTargetException e) {
                    Throwable meaningEx = e instanceof InvocationTargetException
                        ? ((InvocationTargetException) e).getTargetException() : e;
                    getComponent(IHwUncaughtExceptionHandler.class).uncaughtException(Thread.currentThread(),
                        meaningEx);

                    throw new IllegalStateException(meaningEx);
                }
            });
        });
    }

    /**
     * Equip with current request context : all methods will run within current request context if there has one.
     *
     * @param target target
     * @param &lt;T&gt; type
     * @return A callable proxy which delegates all invocations to target within current request context
     */
    @SuppressWarnings(&quot;unchecked&quot;)
    public static &lt;T&gt; Callable&lt;T&gt; equipWithCurrentReqCtx(Callable&lt;T&gt; target) {
        return equipWithCurrentReqCtx(Callable.class, target);
    }

    /**
     * Equip with current request context : all methods will run within current request context if there has one.
     *
     * @param target target
     * @return A runnable proxy which delegates all invocations to target within current request context
     */
    public static Runnable equipWithCurrentReqCtx(Runnable target) {
        return equipWithCurrentReqCtx(Runnable.class, target);
    }

    /**
     * 是否是云侧dm（默认是云侧）
     *
     * @param requestContext {@link RequestContext} 对象
     * @return 是否是云侧dm
     */
    public static boolean isCloudDm(RequestContext requestContext) {
        return Optional.ofNullable(requestContext)
            .map(reqCtx -&gt; (Boolean) reqCtx.getVar(RequestContextKey.IS_CLOUD_DM))
            .orElse(true);
    }

    private static Class&lt;?&gt;[] cls(Class&lt;?&gt;... values) {
        return values;
    }
}
</code></pre>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/22" rel="alternate"/><category term="技术"/><published>2022-10-31T01:56:05+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/21</id><title>哈希表</title><updated>2022-12-15T02:03:42.744807+00:00</updated><content type="html"><![CDATA[<p>###LeteCode刷题</p>
<ul>
<li>题号：1 两数之和</li>
</ul>
<blockquote>
<p>给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target  的那 两个 整数，并返回它们的数组下标。
你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。
你可以按任意顺序返回答案。
示例 1：
输入：nums = [2,7,11,15], target = 9
输出：[0,1]
解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。
示例 2：
输入：nums = [3,2,4], target = 6
输出：[1,2]
示例 3：
输入：nums = [3,3], target = 6
输出：[0,1]</p>
</blockquote>
<pre><code>
class Solution {
    public int[] twoSum(int[] nums, int target) {
        Map&lt;Integer, Integer&gt; res = new HashMap&lt;&gt;();
        for (int i = 0; i &lt; nums.length; i++) {
            if (res.containsKey(target - nums[i])) {
                return new int[]{i, res.get(target - nums[i])};
            } else {
                res.put(nums[i], i);
            }
        }
        return new int[]{};

    }
}
</code></pre>
<ul>
<li>题号：454</li>
</ul>
<blockquote>
<p>给你四个整数数组 nums1、nums2、nums3 和 nums4 ，数组长度都是 n ，请你计算有多少个元组 (i, j, k, l) 能满足：
0 &lt;= i, j, k, l &lt; n
nums1[i] + nums2[j] + nums3[k] + nums4[l] == 0
示例 1：
输入：nums1 = [1,2], nums2 = [-2,-1], nums3 = [-1,2], nums4 = [0,2]
输出：2
解释：
两个元组如下：</p>
</blockquote>
<ol>
<li>(0, 0, 0, 1) -&gt; nums1[0] + nums2[0] + nums3[0] + nums4[1] = 1 + (-2) + (-1) + 2 = 0</li>
<li>(1, 1, 0, 0) -&gt; nums1[1] + nums2[1] + nums3[0] + nums4[0] = 2 + (-1) + (-1) + 0 = 0
示例 2：
输入：nums1 = [0], nums2 = [0], nums3 = [0], nums4 = [0]
输出：1</li>
</ol>
<pre><code>class Solution {
    public int fourSumCount(int[] nums1, int[] nums2, int[] nums3, int[] nums4) {
        Map&lt;Integer, Integer&gt; map1 = new HashMap&lt;&gt;();
        Map&lt;Integer, Integer&gt; map2 = new HashMap&lt;&gt;();
        for (int i = 0; i&lt; nums1.length; i++){
            for (int j = 0; j&lt; nums1.length;j++){
                int res1 = nums1[i] + nums2[j];
                map1.put(res1,map1.getOrDefault(res1,0) +1); 
                int res2 = nums3[i] + nums4[j];
                map2.put(res2,map2.getOrDefault(res2,0) +1);
               
            }

        }

        int count = 0;
        for (Map.Entry&lt;Integer, Integer&gt; entry: map1.entrySet()){
            if (map2.containsKey(0- entry.getKey())){
                count+= entry.getValue() * map2.get(0-entry.getKey());
            }
        }

        return count;
    }
}

代码可以进行优化：

class Solution {
    public int fourSumCount(int[] A, int[] B, int[] C, int[] D) {
        Map&lt;Integer, Integer&gt; countAB = new HashMap&lt;Integer, Integer&gt;();
        for (int u : A) {
            for (int v : B) {
                countAB.put(u + v, countAB.getOrDefault(u + v, 0) + 1);
            }
        }
        int ans = 0;
        for (int u : C) {
            for (int v : D) {
                if (countAB.containsKey(-u - v)) {
                    ans += countAB.get(-u - v);
                }
            }
        }
        return ans;
    }
}
</code></pre>
<ul>
<li>题目：560</li>
</ul>
<blockquote>
<p>给你一个整数数组 nums 和一个整数 k ，请你统计并返回 该数组中和为 k 的连续子数组的个数 。
示例 1：</p>
</blockquote>
<p>输入：nums = [1,1,1], k = 2
输出：2
示例 2：</p>
<p>输入：nums = [1,2,3], k = 3
输出：2</p>
<p>思路：我们定义 <code>pre[i]</code> 为 [0..i] 里所有数的和，则<code>pre[i]</code> 可以由 <code>pre[i−1]</code> 递推而来，即：
<code>pre[i]=pre[i−1]+nums[i]</code>
那么<code>[j..i]</code> 这个子数组和为 k这个条件我们可以转化为
<code>pre[i]−pre[j−1]==k</code>
简单移项可得符合条件的下标 j 需要满足
<code>pre[j−1]==pre[i]−k</code>
先从前缀和代码开始进行编写：</p>
<pre><code> public int subarraySum(int[] nums, int k) {
        int len = nums.length;
        // 计算前缀和数组
        int[] preSum = new int[len + 1];
        preSum[0] = 0;
        for (int i = 0; i &lt; len; i++) {
            preSum[i + 1] = preSum[i] + nums[i];
        }

        int count = 0;
       //遍历前缀和数组，找到满足条件的
        for (int left = 0; left &lt; len; left++) {
            for (int right = left; right &lt; len; right++) {
                // 区间和 [left..right]，注意下标偏移
                if (preSum[right + 1] - preSum[left] == k) {
                    count++;
                }
            }
        }
        return count;
    }

</code></pre>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/21" rel="alternate"/><category term="算法"/><published>2022-10-30T11:25:24+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/20</id><title>wait和notify</title><updated>2022-12-15T02:03:42.823970+00:00</updated><content type="html"><![CDATA[<ul>
<li>wait
线程处于阻塞状态</li>
<li>notify
唤醒其他处于阻塞线程
以生产-消费者模型为例子，伪代码如下：</li>
</ul>
<pre><code>public void dequeue(){
      synchronized(queue){
        while(queue.empty()){
            queue.wait();
        }

    //数据出列
   queue.notify();
    }
}


public void  enequeue(){
      synchronized(queue){
        while(queue.full()){
            queue.wait();
        }

    //数据入列
   queue.notify();
    }
}
</code></pre>
<p>生产者在通知消费者的同时，也通知了其他处于阻塞状态的生产者（多线程下），消费者在通知生产者的同时，也通知了其他消费者。原因在于：<strong>wait和notify所作用的对象和synchronized所作用的对象是同一个，只能有一个对象，无法区分队列空和队列满的两个条件。这正是Condition所解决的问题</strong></p>
<h3>使用Condition和ReentrantLock简单实现阻塞队列</h3>
<pre><code>package threadLearn.notifyDemo.condition;

import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.ReentrantLock;

/**
 * 参照的是ArrayBlockingQueue实现消费-生产者模型，lock配合condition用于区分队列空与队列满的条件
 *
 * @author Ma
 * @version 1.0
 * @date 2022/10/30 17:25
 */
public class MyBlockingQueue {
    private ReentrantLock lock;
    private Condition notEmpty;
    private Condition notFull;

    private int count;
    private int takeIndex;
    private int putIndex;
    final String[] items;

    public MyBlockingQueue(int count) {
        this.count = count;
        this.items = new String[count];
        lock = new ReentrantLock();
        notEmpty = lock.newCondition();
        notFull = lock.newCondition();
    }

    public void put(String item) throws InterruptedException {
        lock.lock();
        try {
            while (count == items.length) {
                System.out.println(&quot;-----生产者被阻塞&quot;);
                notFull.await();
            }
            items[putIndex] = item;
            ++count;
            ++putIndex;
            if (putIndex == items.length) {
                putIndex = 0;
            }
            notEmpty.signal();
        } finally {
            lock.unlock();
        }
    }
    public String get() throws InterruptedException {
        lock.lock();
        try {
            while (count == 0) {
                System.out.println(&quot;---------消费者被阻塞------&quot;);
                notEmpty.await();
            }
            if (takeIndex == items.length) {
                takeIndex = 0;
            }
            String s = items[takeIndex];
            takeIndex++;
            count--;
            notFull.signal();
            return s;
        } finally {
            lock.unlock();
        }
    }
}
</code></pre>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/20" rel="alternate"/><category term="多线程学习"/><published>2022-10-30T06:21:45+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/19</id><title>多线程基本知识</title><updated>2022-12-15T02:03:42.893032+00:00</updated><content type="html"><![CDATA[<h4>线程状态</h4>
<p>线程状态由Thread.State枚举类来描述，主要有以下几种状态：</p>
<ul>
<li>NEW
此时线程还没还是运行，只是刚创建出来</li>
<li>RUNNABLE</li>
</ul>
<blockquote>
<p>Thread state for a runnable thread.  A thread in the runnable state is executing in the Java virtual machine but it may be waiting for other resources from the operating system such as processor.</p>
</blockquote>
<ul>
<li>BLOCKED</li>
</ul>
<blockquote>
<p>Thread state for a thread blocked waiting for a monitor lock. A thread in the blocked state is waiting for a monitor lock to enter a synchronized block/method or reenter a synchronized block/method after calling {@link Object#wait() Object.wait}</p>
</blockquote>
<ul>
<li>WAITING</li>
</ul>
<blockquote>
<p>/**
* Thread state for a waiting thread.
* A thread is in the waiting state due to calling one of the
* following methods:
* {@link Object#wait() Object.wait} with no timeout
*   {@link #join() Thread.join} with no timeout
*   {@link LockSupport#park() LockSupport.park}
* A thread in the waiting state is waiting for another thread to
* perform a particular action.
*
* For example, a thread that has called <tt>Object.wait()</tt>
* on an object is waiting for another thread to call
* <tt>Object.notify()</tt> or <tt>Object.notifyAll()</tt> on
* that object. A thread that has called <tt>Thread.join()</tt>
* is waiting for a specified thread to terminate.
*/</p>
</blockquote>
<ul>
<li>TIMED_WAITING</li>
</ul>
<blockquote>
<p>/**
* Thread state for a waiting thread with a specified waiting time.
* A thread is in the timed waiting state due to calling one of
* the following methods with a specified positive waiting time:
*   {@link #sleep Thread.sleep}
*   {@link Object#wait(long) Object.wait} with timeout
*   {@link #join(long) Thread.join} with timeout
*   {@link LockSupport#parkNanos LockSupport.parkNanos}
*   {@link LockSupport#parkUntil LockSupport.parkUntil}
*/</p>
</blockquote>
<ul>
<li>TERMINATED</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/19" rel="alternate"/><category term="多线程学习"/><published>2022-10-28T07:12:12+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/18</id><title>RPC学习</title><updated>2022-12-15T02:03:42.972466+00:00</updated><content type="html"><![CDATA[<p>socket，又称<strong>套接字</strong>，是在不同的进程间进行网络通讯的一种协议、约定或者说是规范。
对于socket编程，它更多的时候像是基于<strong>TCP/UDP</strong>等协议做的一层封装或者说抽象，是一套系统所提供的用于进行网络通信相关编程的接口。
java中使用socket编程主要分为客户端和服务器端代码，demo如下：</p>
<pre><code>public class ClientDemo {
    public static void main(String[] args) throws Exception {
        while(true){
            Socket socket = new Socket(&quot;127.0.0.1&quot;, 9999);
            OutputStream os = socket.getOutputStream();
            System.out.println(&quot;请输入：&quot;);
            Scanner scanner = new Scanner(System.in);
            String msg = scanner.nextLine();
            os.write(msg.getBytes());
            InputStream inputStream = socket.getInputStream();
            byte[] bytes = new byte[1024];
            int read = inputStream.read(bytes);
            System.out.println(&quot;老板说：&quot; + new String(bytes,0,read).trim());

        }
    }
}


public class ServerDemo {
    public static void main(String[] args) throws Exception {
        ExecutorService executorService = Executors.newCachedThreadPool();
        ServerSocket serverSocket = new ServerSocket(9999);

        System.out.println(&quot;服务器已经启动&quot;);

        while (true) {
            final Socket socket = serverSocket.accept();
            System.out.println(&quot;有客户端连接&quot;);
            executorService.execute(new Runnable() {
                public void run() {
                    handle(socket);
                }
            });
        }
    }

    private static void handle(Socket socket) {
        try {
            System.out.println(&quot;线程ID: &quot; + Thread.currentThread().getId() + &quot;  线程名称： &quot; + Thread.currentThread().getName());
            InputStream inputStream = socket.getInputStream();
            byte[] bytes = new byte[1024];
            int read = inputStream.read(bytes);
            System.out.println(&quot;客户端输入内容为: &quot; + new String(bytes, 0, read).trim());
            OutputStream outputStream = socket.getOutputStream();
            OutputStream os = socket.getOutputStream();
            System.out.println(&quot;请输入：&quot;);
            Scanner scanner = new Scanner(System.in);
            String msg = scanner.nextLine();
            outputStream.write(msg.getBytes());

        } catch (Exception e) {

        }
    }
}
</code></pre>
<p><img src="https://user-images.githubusercontent.com/22972346/197768649-9fff47bd-220c-4341-8933-d574aa0c92d1.png" alt="image" /></p>
<h2>I/O模型</h2>
<ul>
<li>BIO
同步并阻塞</li>
<li>NIO
同步非阻塞</li>
<li>AIO
异步非阻塞
接下来主要熟悉下Java中的NIO
同步非阻塞，服务器实现模式为一个线程处理多个请求连接，即客户端发送的请求连接都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时候就会进行处理。
<img src="https://user-images.githubusercontent.com/22972346/197769207-18e34ba1-a45d-47b9-b66f-0f6b952d95a4.png" alt="image" /></li>
</ul>
<h3>NIO组件</h3>
<p><img src="https://user-images.githubusercontent.com/22972346/197769396-f6baf1f9-4dca-456f-ade3-59b26225a5df.png" alt="image" /></p>
<ul>
<li>Selector</li>
<li>Channel</li>
<li>
Buffer
<img src="https://user-images.githubusercontent.com/22972346/197769535-44ce624f-09ab-438f-af97-63c6e5dd9e62.png" alt="image" /><ul>
<li>
创建<ul>
<li>使用allocate方法创建指定长度的缓冲区</li>
<li>使用wrap创建指定内容的缓冲区</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/18" rel="alternate"/><category term="Nio和Netty学习"/><published>2022-10-25T12:11:44+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/17</id><title>Java 服务CPU占用高时问题定位方法</title><updated>2022-12-15T02:03:43.057703+00:00</updated><content type="html"><![CDATA[<p>本文提供了一种比较简单的方法来定位CPU高罪魁祸首代码，在CPU占用高的时候，可以通过以下方法，尽快定位相应的代码行</p>
<h1>1.找到占用cpu高的进程</h1>
<p>执行top 命令，找到占用CPU高的进程72471
如下图
<img src="https://user-images.githubusercontent.com/22972346/194806395-fd5796cb-8bf0-4c1c-a00e-c4fa03175aab.png" alt="image" /></p>
<h1>2.执行top -H -p 进程号，找到占用CPU最高的线程号129204，转换成16进制1f8b4</h1>
<p><img src="https://user-images.githubusercontent.com/22972346/194806428-22da948d-e858-46a0-8e26-cf4b6ac33d1c.png" alt="image" /></p>
<h1>3.执行jstack 72471 &gt;72471.log 用来dump出目前代码栈</h1>
<h1>4. 从72471.log 中根据线程号 1f8b4 查找其中的线程相应的代码栈，则可快速定位相应的业务代码</h1>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/17" rel="alternate"/><category term="技术"/><published>2022-10-10T06:02:39+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/16</id><title>SQL 语法简单检查</title><updated>2022-12-15T02:03:43.130610+00:00</updated><content type="html"><![CDATA[<p>最近遇到一个场景。每次版本升级时，要把增量sql放入配置文件里，同时把增量sql的文件内容，同步到全量sql里。这个过程中，如果由于手误等其他各种人为原因，可能导致sql错误，进而导致后期转测存在问题</p>
<p>怎么解决呢，最好的办法在代码review阶段，能够检查出语法错误。</p>
<p>重复造轮子是不现实的。你要检查sql的语法，这个难度相对比较大。这个时候我们发现了<a href="https://github.com/alibaba/druid/wiki/SQL-Parser">Druid MySQL Parser</a></p>
<blockquote>
<p>SQL Parser是Druid的一个重要组成部分，Druid内置使用SQL Parser来实现防御SQL注入（WallFilter）、合并统计没有参数化的SQL(StatFilter的mergeSql)、SQL格式化、分库分表。</p>
</blockquote>
<blockquote>
<p>Druid SQL Parser分三个模块：
Parser parser是将输入文本转换为ast（抽象语法树），parser有包括两个部分，Parser和Lexer，其中Lexer实现词法分析，Parser实现语法分析。
<a href="https://github.com/alibaba/druid/wiki/Druid_SQL_AST">AST</a> AST是Abstract Syntax Tree的缩写，也就是抽象语法树。AST是parser输出的结果
Visitor Visitor是遍历AST的手段，是处理AST最方便的模式</p>
</blockquote>
<p>有了以上功能，我们就可以构建我们自己的sql语法校验模 块了</p>
<p>1.创建一个UT 模块</p>
<p>2.检查sql语法</p>
<p>1.根据文件解析出sql，按分号分割</p>
<pre><code>@Before
public void setUp() throws IOException {
    File f = new File(&quot;123.sql&quot;);
    String allSql = Files.toString(f, Charset.forName(&quot;UTF-8&quot;));
        //根据分号，分割出每一行sql
    sqlList = allSql.split(&quot;;&quot;);
}
</code></pre>
<p>2.根据druid提供的功能校验sql</p>
<pre><code>private List&lt;SqlInfo&gt; getResults(String sql){
    List&lt;SqlInfo&gt; results = new ArrayList&lt;SqlInfo&gt;();
    MySqlStatementParser parser = new MySqlStatementParser(sqls);
    //使用parser 把sql文本转换成AST(抽象语法树)
    List&lt;SQLStatement&gt; stmtList = parser.parseStatementList();
    StringBuilder out = new StringBuilder();
    //使用vistor模式访问AST
    MySqlOutputVisitor visitor = new MySqlOutputVisitor(out);
    for (SQLStatement stmt : stmtList) {
        SqlInfo sqlDto = new SqlInfo();
        stmt.accept(visitor);
        out.append(&quot;;&quot;);
        sqlDto.setSql(out.toString());
        results.add(sqlDto);
    }
    return results;
}
</code></pre>
<p>3.执行test,如果语法校验不通过，会抛出异常</p>
<pre><code>@Test
public void testDataSQL() {
    for (String sql : sqlList) {
        List&lt;SqlInfo&gt; sqlOutput = getResults(sql);
        for (SqlInfo dto : sqlOutput) {
            System.out.println(dto.sql);
        }
    }
}
</code></pre>
<p>编译阶段，自动执行单元测试，就可以有效的减少由人为失误，导致的sql语法问题了</p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/16" rel="alternate"/><category term="技术"/><published>2022-10-10T05:56:36+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/15</id><title>Redis持久化</title><updated>2022-12-15T02:03:43.217557+00:00</updated><content type="html"><![CDATA[<p>Redis持久化主要有两大机制：<strong>AOF</strong>和<strong>RDB</strong></p>
<ul>
<li>
AOF记录的是<strong>Redis收到的每一条指令</strong>，以文本形式进行保存。<ul>
<li>好处：命令执行完之后才记录日志，所以<strong>不会阻塞当前的写操作</strong></li>
<li>
潜在风险（与AOF写回磁盘的时机相关）：<ul>
<li>
<p>刚执行完命令即宕机，与该命令相关的数据有丢失的风险</p>
</li>
<li>
<p>避免了当前命令的阻塞，有可能给下一个命令带来阻塞。原因是AOF日志也是在主线程中执行的。</p>
</li>
<li>
<p>写回策略（appendsync）</p>
<ul>
<li>Always 同步写回，命令执行完毕立马同步将日志写回磁盘</li>
<li>Everyec 每秒写回，命令执行完先将日志写到AOF文件的内存缓冲区，每隔一秒将缓冲区的内容写入磁盘</li>
<li>No 操作系统控制的写回</li>
</ul>
</li>
<li>
<p>三种写回策略带来的问题</p>
<ul>
<li>同步写回  数据基本不会丢失，但是在每个命令之后都会有一个慢速的落盘操作，不可避免会影响主线程的性能</li>
<li>操作系统控制写回  写完缓冲区之后，就可以继续执行后续的命令，但是落盘时机已经不在Redis手中，只要AOF记录没有写回磁盘，一旦宕机对应的数据就会丢失</li>
<li>每秒写回 避免了同步写回的性能开销，但是发生宕机，上一秒内未落盘的命令操作依然会丢失</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/22972346/194742536-881e1c9f-32c9-4997-a875-ecccc9b6411f.png" alt="image" />
AOF文件过大带来的性能问题：</p>
<ol>
<li>文件系统本身对文件大小有限制</li>
<li>文件过大时候追加记录效率变慢</li>
<li>故障恢复时缓慢影响使用</li>
</ol>
<h3>如何解决日志文件过大？</h3>
<p>AOF重写机制就是在重写时（什么时候进行重写？），Redis根据数据库现状新建一个新的AOF文件，也就是说读取数据库中的所有键值对，然后用每一个键值用一条命令去记录它的写入。将旧日志文件中的多条命令进行合并（最终效果）</p>
<p>问题1，Redis采用fork子进程重写AOF文件时，潜在的阻塞风险包括：fork子进程 和 AOF重写过程中父进程产生写入的场景，下面依次介绍。
a、fork子进程，fork这个瞬间一定是会阻塞主线程的（注意，fork时并不会一次性拷贝所有内存数据给子进程，老师文章写的是拷贝所有内存数据给子进程，我个人认为是有歧义的），fork采用操作系统提供的写实复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。
b、fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。</p>
<p>问题2，AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可</p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/15" rel="alternate"/><category term="Redis"/><published>2022-10-10T00:56:18+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/14</id><title>redis学习 day1</title><updated>2022-12-15T02:03:43.303833+00:00</updated><content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/22972346/192457217-11f702fe-76e2-492e-81ee-714beedfdf16.png" alt="redis问题画像" /></p>
<h2>Redis的支持的数据</h2>
<ul>
<li>String</li>
<li>List</li>
<li>hash</li>
<li>Set</li>
<li>Sorted Set
对应的底层数据结构：
<img src="https://user-images.githubusercontent.com/22972346/192484398-fc7b2566-08da-422f-a73f-0a102580aa38.png" alt="数据结构对应" /></li>
</ul>
<h4>redis的数据存储</h4>
<p>为了实现从键到值得快速访问，Redis使用了一个<strong>哈希表</strong>来保存<strong>所有的键值对</strong>
<img src="https://user-images.githubusercontent.com/22972346/192484849-e6a31518-f7d1-4275-b490-c1c37c64a7c7.png" alt="全局哈希表" /></p>
<p>哈希表具有**O(1)**的复杂度和快速查找特性，但是也会遇到问题：</p>
<ol>
<li><strong>哈希表的哈希冲突</strong>
解决方案：哈希冲突链，类比java中hashMap中的哈希冲突解决方案
问题：冲突链过长时候查询退化成<strong>O(n)</strong></li>
<li><strong>rehash可能带来的操作阻塞</strong>
解决方案：使用两个全局哈希表，其中一个在rehash时候进行切换
问题：数据迁移时候会造成Redis线程阻塞。
解决：
渐进式rehash</li>
</ol>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/14" rel="alternate"/><category term="Redis"/><published>2022-09-27T09:06:19+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/13</id><title>服务无法启动-oom问题</title><updated>2022-12-15T02:03:43.384052+00:00</updated><content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/22972346/189820555-f4be6124-bc4e-4c87-a07f-548a5cd8480f.png" alt="7C1B6017-539E-4350-A1DC-0DEE0C7CAF11" />
排查思路：日志中显示启动内存不足</p>
<ul>
<li>登陆服务器，使用<strong>free -m</strong>查看服务器内存使用情况
<img src="https://user-images.githubusercontent.com/22972346/189821679-dfbbc60b-f9ac-4aa3-ab24-77362d8a1a63.png" alt="image" />
然后看下启动脚本中**-Xmx -Xms**的参数配置
<img src="https://user-images.githubusercontent.com/22972346/189821311-676bf12f-6eb6-45c3-a092-b75a9ae6d706.png" alt="image" />
发现是由于配置的堆内存的大小远大于服务器存储剩余存储空间，导致服务无法启动。
将该参数改成比服务器剩余内存空间较小的值，服务顺利启动。</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/13" rel="alternate"/><category term="技术"/><published>2022-09-13T06:00:20+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/12</id><title>垃圾收集器</title><updated>2022-12-15T02:03:43.468635+00:00</updated><content type="html"><![CDATA[<h2>对象死亡判断</h2>
<ul>
<li>
<p>引用计数法
给对象设置一个<strong>引用计数器</strong>，每当对象被引用就+1，引用失效-1.
-&gt; 很难解决对象之间循环引用的问题</p>
</li>
<li>
<p>可达性分析算法
基本思路是通过一系列的“GC Roots&quot;对象作为起点，从这些节点开始向下进行搜索，搜索的路径成为<strong>引用链</strong>.当一个对象到GC Roots没有任何引用链时，则该对象不可用。</p>
<ul>
<li>
GC Roots对象
<strong>两栈两方法</strong><ul>
<li>虚拟机栈（本地变量表）中引用的对象</li>
<li>本地方法栈中JNI引用的对象</li>
<li>方法区中静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
</ul>
</li>
<li>
引用的分类<ul>
<li>强引用</li>
<li>软引用
SoftReference类实现软引用。对于软引用关联的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。</li>
<li>弱引用
被弱引用关联的对象只能生存到下一次垃圾收集之前。WeakReference</li>
<li>虚引用
PhantomReference实现虚引用。</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/12" rel="alternate"/><category term="虚拟机"/><published>2022-09-02T01:58:43+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/11</id><title>Java内存区域</title><updated>2022-12-15T02:03:43.547820+00:00</updated><content type="html"><![CDATA[<h2>运行时内存区域</h2>
<ul>
<li>程序计数器
当前线程所执行的字节码的行号指示器。字节码解释器通过程序计数器来选取下一条需要执行的字节码指令。</li>
<li>Java虚拟机栈
<strong>虚拟机栈</strong>描述的时Java方法执行的内存模型：每个方法在执行的时候都会创建一个栈帧，用于存放局部变量表、操作数栈、动态链接和方法出口等信息。</li>
<li>本地方法栈
上述三个属于线程私有的区域</li>
<li>
方法区<ul>
<li>运行时常量池</li>
</ul>
</li>
<li>堆</li>
</ul>
<h2>内寸分配与回收策略</h2>
<ul>
<li>对象优先在Eden分配</li>
<li>大对象直接进入老年代</li>
<li>长期存活的对象进入老年代
虚拟机采用分代的思想管理内存，那么内存回收的时候就必须能够识别哪些对象应该放在新生代，哪些对象应该放在老年代中。为了实现这点，虚拟机给每个对象设置<strong>年龄计数器</strong>。</li>
<li>对象的动态年龄判定
除了年龄计数器值卡，如果在Survivor空间中相同年龄所以对象的总和大于Survivor空间的一般，年龄大于等于该年龄的对象直接进入老年代，无需等到MaxTenuringThreshold中要求的年龄。</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/11" rel="alternate"/><category term="虚拟机"/><published>2022-08-31T01:35:49+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/10</id><title>配置文件热加载</title><updated>2022-12-15T02:03:43.625773+00:00</updated><content type="html"><![CDATA[<ul>
<li>
<p><strong>怎么实现配置文件的热加载</strong>？
java1.7中 提供了<strong>WatchService</strong>来监控系统中文件的变化。该监控是基于操作系统的文件系统监控器，可以监控系统是所有文件的变化，这种监控是无需遍历、无需比较的，是一种基于信号收发的监控，因此效率一定是最高的；现在Java对其进行了包装，可以直接在Java程序中使用OS的文件系统监控器了。</p>
</li>
<li>
<p><strong>使用场景</strong>
场景一：比如系统中的配置文件，一般都是系统启动的时候只加载一次，如果想修改配置文件，还须重启系统。如果系统想热加载一般都会定时轮询对比配置文件是否修改过，如果修改过重新加载。
场景二：监控磁盘中的文件变化，一般需要把磁盘中的所有文件全部加载一边，定期轮询一遍磁盘，跟上次的文件状态对比。如果文件、目录过多，每次遍历时间都很长，而且还不是实时监控。</p>
</li>
<li>
<p><strong>实现思路</strong>
监控文件修改及创建事件</p>
</li>
</ul>
<pre><code>import java.io.File;
import java.io.IOException;
import java.net.URI;
import java.net.URISyntaxException;
import java.nio.file.FileSystems;
import java.nio.file.Path;
import java.nio.file.StandardWatchEventKinds;
import java.nio.file.WatchEvent;
import java.nio.file.WatchKey;
import java.nio.file.WatchService;
import java.util.Arrays;
import java.util.HashSet;
import java.util.Map;
import java.util.Objects;
import java.util.Set;
import java.util.function.Consumer;

import javax.annotation.PostConstruct;

import org.springframework.context.annotation.Configuration;
import org.springframework.scheduling.annotation.EnableScheduling;
import org.springframework.scheduling.annotation.Scheduled;

import com.google.common.collect.Maps;

import lombok.extern.slf4j.Slf4j;

/**
 * 自动热加载配置类
 *
 * @author c00566803
 * @since 2022-08-15
 */
@Configuration
@EnableScheduling
@Slf4j
public class AutoReloadConfiguration {
    /**
     * 文件监测时间间隔，默认1分钟
     */
    public static final long WATCH_INTERVAL = 60 * 1000;

    private static final String PREFIX_FILE = &quot;.&quot;;

    private WatchService watchService;

    private Map&lt;String, Consumer&lt;WatchEvent.Kind&lt;Path&gt;&gt;&gt; consumers = Maps.newHashMap();

    /**
     * 初始化方法
     */
    @PostConstruct
    public void init() {
        try {
            watchService = FileSystems.getDefault().newWatchService();

            // 默认监控classpath下面所有文件和子目录的变化
            URI uri = AutoReloadConfiguration.class.getResource(&quot;/&quot;).toURI();
            File baseDir = new File(uri);
            File[] childDirs = baseDir.listFiles(File::isDirectory);
            Set&lt;File&gt; watchedDirs = new HashSet&lt;&gt;();
            watchedDirs.add(baseDir);
            if (Objects.nonNull(childDirs)) {
                Arrays.asList(childDirs).forEach(file -&gt; watchedDirs.add(file));
            }
            for (File dir : watchedDirs) {
                Path path = dir.toPath();
                log.info(&quot;watch path {}&quot;, path);

                // 监控文件修改及创建事件
                path.register(watchService, StandardWatchEventKinds.ENTRY_MODIFY, StandardWatchEventKinds.ENTRY_CREATE);
            }
        } catch (IOException | URISyntaxException e) {
            log.error(&quot;error while register watch service&quot;);
        }
    }

    /**
     * 注册监听文件
     *
     * @param filePath 文件全路径
     * @param consumer 回调事件
     */
    public void register(String filePath, Consumer&lt;WatchEvent.Kind&lt;Path&gt;&gt; consumer) {
        log.info(&quot;register watch service of {}&quot;, filePath);
        if (Objects.isNull(filePath)) {
            log.warn(&quot;{} is not regular file&quot;, filePath);
        } else {
            consumers.put(filePath, consumer);
            consumers.put(PREFIX_FILE + filePath, consumer);
        }
    }

    /**
     * 定时任务
     */
    @Scheduled(fixedRate = WATCH_INTERVAL)
    public void watch() {
        WatchKey key = watchService.poll();
        if (Objects.nonNull(key)) {
            Map&lt;String, WatchEvent.Kind&lt;Path&gt;&gt; changedFiles = getChangedFiles(key);

            // 处理所有文件变化的事件
            changedFiles.forEach((s, kind) -&gt; {
                if (consumers.containsKey(s)) {
                    log.info(&quot;reload file {}&quot;, s);
                    consumers.get(s).accept(kind);
                }
            });

            // 此处必须reset，不然后续事件无法获取
            key.reset();
        }
    }

    private Map&lt;String, WatchEvent.Kind&lt;Path&gt;&gt; getChangedFiles(WatchKey key) {
        Map&lt;String, WatchEvent.Kind&lt;Path&gt;&gt; changedFiles = Maps.newHashMap();

        // 获取所有变化的文件，一个文件多次变化默认取最后一个事件
        for (WatchEvent&lt;?&gt; event : key.pollEvents()) {
            log.info(&quot;Event kind: {}. File affected: {}.&quot;, event.kind(), event.context());
            if (event.context() instanceof Path) {
                Path path = (Path) event.context();
                Path fileName = path.getFileName();
                if (Objects.isNull(fileName)) {
                    log.warn(&quot;{} is not regular file&quot;, path);
                } else {
                    changedFiles.put(fileName.toString(), getKind(event));
                    log.info(&quot;fileName: {}.&quot;, fileName);
                }
            }
        }
        return changedFiles;
    }

    @SuppressWarnings({&quot;unchecked&quot;})
    private WatchEvent.Kind&lt;Path&gt; getKind(WatchEvent&lt;?&gt; event) {
        return (WatchEvent.Kind&lt;Path&gt;) event.kind();
    }
}
</code></pre>
<p>配置类：</p>
<pre><code>import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.nio.file.Path;
import java.nio.file.WatchEvent;
import java.util.Properties;
import java.util.function.Consumer;

import javax.annotation.PostConstruct;

import org.springframework.beans.BeanUtils;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import com.alibaba.fastjson.JSON;
import com.alibaba.fastjson.JSONObject;

import lombok.extern.slf4j.Slf4j;

/**
 * 热加载相关配置
 *
 * @author c00566803
 * @since 2022-08-15
 */
@Slf4j
@Component
public class HotLoadConfiguration {
    private String configFile = &quot;visualization.properties&quot;;

    @Autowired
    private HotLoadProperties hotLoadProperties;

    @Autowired
    private AutoReloadConfiguration autoReloadConfiguration;

    /**
     * 初始化函数
     *
     * @throws IOException IO异常
     */
    @PostConstruct
    public void init() {
        try {
            reloadConfig();
        } catch (IOException e) {
            log.error(&quot;配置文件加载异常&quot;);
        }
        register();
    }


    //加载配置文件
    private void reloadConfig() throws IOException {
        Properties properties = new Properties();
        try (InputStream resource = ClassLoader.getSystemResourceAsStream(configFile)) {
            InputStreamReader inputStreamReader = new InputStreamReader(resource, &quot;UTF-8&quot;);
            properties.load(inputStreamReader);
            String config = JSON.toJSONString(properties);
            log.info(&quot;before hotLoadProperties = &quot; + hotLoadProperties);
            HotLoadProperties configSource = JSONObject.parseObject(config, HotLoadProperties.class);
            BeanUtils.copyProperties(configSource, hotLoadProperties);
            inputStreamReader.close();
            log.info(&quot;after hotLoadProperties = &quot; + hotLoadProperties);
            log.info(&quot;success read config : {}&quot;, configFile);
        }
    }

    private void register() {
        Consumer&lt;WatchEvent.Kind&lt;Path&gt;&gt; consumer = kind -&gt; {
            try {
                reloadConfig();
            } catch (IOException e) {
                log.error(&quot;reload failed&quot;, e);
            }
        };

        // visualization.properties配置文件
        autoReloadConfiguration.register(configFile, consumer);
    }
}

</code></pre>
<pre><code>import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.PropertySource;
import org.springframework.stereotype.Component;

import com.alibaba.fastjson.annotation.JSONField;

import lombok.Getter;
import lombok.Setter;
import lombok.ToString;

/**
 * HotLoadProperties 热加载属性
 *
 * @author c00566803
 * @since 2022-08-15
 */
@Configuration
@PropertySource(&quot;classpath:visualization.properties&quot;)
@Component
@Getter
@Setter
@ToString
public class HotLoadProperties {
    @Value(&quot;${task.hag.server}&quot;)
    @JSONField(name = &quot;task.hag.server&quot;)
    private String hagServer;
}

</code></pre>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/10" rel="alternate"/><category term="技术"/><published>2022-08-17T07:40:30+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/9</id><title>记SpringBoot从2.5.8升级到2.6.7遇到的循环依赖问题</title><updated>2022-12-15T02:03:43.704343+00:00</updated><content type="html"><![CDATA[<p>在SpringBoot升级完成之后，项目启动遇到问题，报了这么一个错误：
<img src="https://user-images.githubusercontent.com/22972346/171575651-1280e4f6-6317-41c3-8703-9816f7f7a0db.png" alt="image" /></p>
<blockquote>
<p>Action:
Relying upon circular references is discouraged and they are prohibited by default. Update your application to remove the &gt; dependency cycle between beans. As a last resort, it may be possible to break the cycle automatically by setting &gt; spring.main.allow-circular-references to true</p>
</blockquote>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/9" rel="alternate"/><category term="技术"/><published>2022-06-02T07:08:35+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/8</id><title>Head和Body相关</title><updated>2022-12-15T02:03:43.775938+00:00</updated><content type="html"><![CDATA[<h2>HTTP的实体数据</h2>
<p>####数据类型使用的头字段</p>
<ul>
<li><strong>Accept/Accept-Encoding</strong></li>
<li><strong>Content-Type/Content-Encoding</strong></li>
</ul>
<h4>语言类型与字符集</h4>
<ul>
<li><strong>Accept-Language/Accept-Charset</strong>字段标记了客户端可理解的自然语言与字符集</li>
<li>服务器应该在响应报文里用头字段<strong>Content-Language</strong>告诉客户端实体数据使用的实际语言类型。响应头里却没有对应的Content-Charset，而是在Content-Type字段的数据类型后面用“charset=xxx”来表示，这点需要特别注意</li>
</ul>
<pre><code class="language-java">Accept-Charset: gbk, utf-8
Content-Type: text/html; charset=utf-8
</code></pre>
<h2>HTTP大文件传输</h2>
<ul>
<li>压缩</li>
<li>分块传输
使用&quot;chunked&quot;分块传输编码，在响应头中用头字段**&quot;Transfer-Encoding:chunked&quot;**表示</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/8" rel="alternate"/><category term="HTTP相关"/><published>2022-05-27T01:10:20+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/7</id><title>相应状态码</title><updated>2022-12-15T02:03:43.857620+00:00</updated><content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/22972346/170392132-39e0193a-d7a2-4b67-b515-2eae48bf658b.png" alt="image" /></p>
<ul>
<li>1××：提示信息，表示目前是协议处理的中间状态，还需要后续的操作；</li>
<li>2××：成功，报文已经收到并被正确处理；
<strong>200 OK</strong>
<strong>204 Not Content</strong>：与200基本相同，但是响应头后没有body数据
<strong>206 Partial Content</strong>：服务器成功处理请求，但是body中的数据不是全部资源，二十其中的一部分，是HTTP分块下载或断点续传的基础。通常会伴随头部字段“Content-Range”，表示相应报文中body数据的具体范围。例如“Content-Range: bytes 0-99/2000”，意思是此次获取的是总计2000个字节的前100个字节</li>
<li>3××：重定向，资源位置发生变动，需要客户端重新发送请求；
**“301 Moved Permanently”**俗称“永久重定向”，含义是此次请求的资源已经不存在
了，需要改用新的URI再次访问。</li>
</ul>
<p>与它类似的是“302 Found”，曾经的描述短语是“Moved Temporarily”，俗称“临时重定向”，意思是请求的资源还在，但需要暂时用另一个URI来访问。</p>
<ul>
<li>
<p>4××：客户端错误，请求报文有误，服务器无法处理；
**“400 Bad Request”**是一个通用的错误码，表示请求报文有错误，但具体是数据格式错误、缺少请求头还是URI超长它没有明确说，只是一个笼统的错误，客户端看到400只会是“一头雾水”“不知所措”。所以，在开发Web应用时应当尽量避免给客户端返回400，而是要用其他更有明确含义的状态码。</p>
<p>**“403 Forbidden”**实际上不是客户端的请求出错，而是表示服务器禁止访问资
源。原因可能多种多样，例如信息敏感、法律禁止等，如果服务器友好一点，可以
在body里详细说明拒绝请求的原因，不过现实中通常都是直接给一个“闭门羹”。</p>
</li>
</ul>
<p>**“404 Not Found”**可能是我们最常看见也是最不愿意看到的一个状态码，它的原意是资源在本服务器上未找到，所以无法提供给客户端</p>
<ul>
<li>5××：服务器错误，服务器在处理请求时内部发生了错误
**“500 Internal Server Error”**与400类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析。</li>
</ul>
<p>**“501 Not Implemented”**表示客户端请求的功能还不支持，这个错误码比500要“温和”一些，和“即将开业，敬请期待”的意思差不多，不过具体什么时候“开业”就不好说了。</p>
<p>**“502 Bad Gateway”**通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的。</p>
<p>**“503 Service Unavailable”**表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码503。</p>
<p>503是一个“临时”的状态，很可能过几秒钟后服务器就不那么忙了，可以继续提供服务，所以503响应报文里通常还会有一个“Retry-After”字段，指示客户端可以在多久以后再次尝试发送请求。</p>
<h2>HTTP协议的特点</h2>
<ul>
<li>1.HTTP是灵活可扩展的，可以任意添加头字段实现任意功能；</li>
<li>2.HTTP是可靠传输协议，基于TCP/IP协议“尽量”保证数据的送达；</li>
<li>3.HTTP是应用层协议，比FTP、SSH等更通用功能更多，能够传输任意数据；</li>
<li>4.HTTP使用了请求-应答模式，客户端主动发起请求，服务器被动回复请求；</li>
<li>5.HTTP本质上是无状态的，每个请求都是互相独立、毫无关联的，协议不要求客户端或服务器记录请求相关的信息。</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/7" rel="alternate"/><category term="HTTP相关"/><published>2022-05-26T00:50:32+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/6</id><title>请求方法</title><updated>2022-12-15T02:03:43.950298+00:00</updated><content type="html"><![CDATA[<h2>标准请求方法</h2>
<p>目前HTTP/1.1规定了八种方法：</p>
<ul>
<li><strong>GET</strong>   获取数据</li>
<li><strong>HEAD</strong> 获取资源的元数据</li>
<li><strong>POST</strong>  像资源提交数据，相当于上传或写入</li>
<li><strong>PUT</strong>  类post</li>
<li>DELETE</li>
<li>CONNECT 建立特殊的连接隧道</li>
<li>OPTIONS 列出可对资源实行的方法</li>
<li>TRACE 最总请求-相应的传输路径</li>
</ul>
<h2>安全和幂等</h2>
<p>安全：在HTTP协议中，<strong>安全</strong>是指请求方法不会破坏服务器上的资源，即不会对服务器上的资源造成实质的修改
幂等：多次执行相同的操作，姐夫哦也都是相同的。</p>
<h2>URI格式</h2>
<p><img src="https://user-images.githubusercontent.com/22972346/170390312-0d76f62d-9702-43d4-b864-837d06961120.png" alt="image" /></p>
<ul>
<li><strong>schema</strong>:协议名，规定资源应该使用哪种协议来访问</li>
<li>://之后是**“authority”<strong>部分，表示</strong>资源所在的主机名**，通常采用‘’host:port&quot;的形式。HTTP默认端口号为80，HTTPS默认端口号为443</li>
<li>标记资源所在位置的path
<img src="https://user-images.githubusercontent.com/22972346/170391320-d4f8abe7-e655-4dce-a0d0-93fb4ec4fc65.png" alt="image" /></li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/6" rel="alternate"/><category term="HTTP相关"/><published>2022-05-25T09:49:21+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/2</id><title>HTTP专栏学习</title><updated>2022-12-15T02:03:44.045540+00:00</updated><content type="html"><![CDATA[<h3>名词解释</h3>
<ul>
<li>CND
Content Delivery Network，内容分发网络，工作在客户端和服务器之间，它应用了HTTP协议里的缓存和代理技术，代替源站响应客户端的请求，主要起到缓存加速的作用。</li>
<li>URI
Uniform Resource Identifier，统一资源标识符。其组成部分为：
<code>http://nginx.org/en/download.html</code>
1.协议名
2.主机名
3.路径</li>
<li>代理 Proxy
是HTTP协议中请求方和应答方中间的一个环节。代理种类一般分为：
1.匿名代理
2.透明代理
3.正向代理
4.反向代理，代表服务器相应客户端请求</li>
</ul>
<h3>什么是http?</h3>
<p>HTTP就是<strong>超文本传输协议</strong>，也就是<strong>HyperText Transfer Protocol</strong>
通俗一点的解释是：HTTP是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范</p>
<blockquote>
<p>Q:有一种流行的说法：“<strong>HTTP是用于从互联网服务器传输超文本到本地浏览器的协议</strong>”，你认为这种说法对吗？对在哪里，又错在哪里？</p>
</blockquote>
<blockquote>
<p>A:这种说法是不对的。HTTP是互联网中两点之间传输超文本的协议，这两点指的是浏览器-服务器，服务器-服务器和服务器到浏览器，浏览器-浏览器之间是不能用http协议的。且两点之间可以有其他的“中转”。除此之外，http不是协议栈，它是运行在TCP/IP协议上栈上的协议.
Q:DNS(domain name system)和URI的关系是什么</p>
</blockquote>
<blockquote>
<p>A:DNS与URI的的关系： URI用来标记互联网资源的名字，方便以后通过这个名字进行访问。它的实现有URL和URN，其中URL规定了访问资源的方式。 在我们利用URL获取资源的时候，如果采用的是主机名的方式则需要对应的转化为IP地址（真实的传输过程中还是采用ip地址进行寻址），这个转换的过程就是DNS域名解析</p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/22972346/164650195-7d4363f7-d4af-478e-9b4e-eb65fa2c4b82.png" alt="image" /></p>
<ul>
<li>请求行
请求行描述的<strong>客户端想要如何操作服务器端的资源</strong>，主要由一下三个部分构成：</li>
</ul>
<ol>
<li>请求方法：GET/POST，表示对资源的操作</li>
<li>请求目标： 通常是一个URI，用于标记请求方法想要操作的资源</li>
<li>版本号：表示报文使用的HTTP协议版本
<img src="https://user-images.githubusercontent.com/22972346/170173361-b602ffa9-2dd4-4b4f-acb5-31b9bb2e982e.png" alt="image" /></li>
</ol>
<p>与<strong>请求行</strong>对应的是相应报文中的<strong>状态行</strong>，意思是<strong>服务器状态的相应</strong>
<img src="https://user-images.githubusercontent.com/22972346/170173534-2c43d6e2-b954-48e9-aea0-8a4e119a48b4.png" alt="image" />
如图所示，状态行也分为三个部分：
1.版本号
2.状态码：一个三位数字，用代码的形式表示处理的结果
3.原因：数字状态码的补充</p>
<ul>
<li><strong>头部字段</strong>
HTTP协议主要分为一下四大类：
1.通用字段
2.请求字段
3.相应字段
4.实体字段</li>
<li>常用字段
<strong>Host</strong>:请求字段，该字段告诉服务器这个请求应该由哪个主机来处理
<strong>User-Agent</strong>：请求字段，使用一个字符串来描述发起HTTP请求得客户端
<strong>Date</strong>：通用字段，通常出现在相应头中，表示HTTP报文创建的时间，客户端据此
再搭配其他字段决定缓存策略。
<strong>Server</strong>：相应字段，告诉客户端当前正在提供Web服务的软件名称和版本号。</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/2" rel="alternate"/><category term="HTTP相关"/><published>2022-04-20T05:56:04+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/1</id><title>消息队列Kafka学习</title><updated>2022-12-15T02:03:44.132026+00:00</updated><content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/22972346/158500100-08edc531-01b9-4060-ab93-87c7d4cc7b7a.png" alt="image" /></p>
<p>这整个下单过程，如果全部同步阻塞，那么耗时会增加，用户等待的时间会加长，体验不太好，同时下单过程依赖的链路越长，风险越大。为了加快响应，减少风险，我们可以把一些非必须卡在主链路中的业务拆解出去，让它们和主业务解耦。下单的最关键核心就是要保证库存、用户支付、商家打款的一致性，消息的通知完全可以走异步。这样整个下单过程不会因为通知商家或者通知用户阻塞而阻塞，也不会因为它们失败而提示订单失败。</p>
<p><img src="https://user-images.githubusercontent.com/22972346/158500145-04bfeb6c-b27f-4688-b465-abe0a8229631.png" alt="image" /></p>
<p>接下来就是如何设计一个消息引擎了，宏观来看一个消息引擎支持发送、存储、接收就行了。
<img src="https://user-images.githubusercontent.com/22972346/158500157-b88a75cc-8057-467d-a44d-c8935359acdc.png" alt="image" /></p>
<p>那么如上图一个简易消息队列模型出现了，Engine把发送方的消息存储起来，这样当接收方来找Engine要数据的时候，Engine再从存储中把数据响应给接收放就ok了。既然涉及到持久化的存储，那么缓慢的磁盘IO是要考虑的问题。还有接收方可能不止一个，以上述订单为例，下单完成之后，通过消息把完成事件发出去，这时候负责用户侧推送的开发需要消费这条消息，负责商户侧推送的开发也需要消费这条消息，能想到的最简单的做法就是copy出两套消息，但是这样是不是显得有点浪费？高可用也是一个需要考虑的点，那么我们的engine是不是得副本，有了副本之后，如果一个engine节点挂掉，我们可以选举出一个新副本来工作。光有副本也不行，发送方可能也是多个，这时候如果所有的发送方都把数据打到一个Leader（主）节点上似乎也不合理，单个节点的压力太大。可能你会说：不是有副本吗？让接收方直接从副本读取消息。这样的话又带来另一个问题：副本复制Leader的消息延迟了咋办？读不到消息再读一次Leader？如果这样的话，引擎的设计的貌似更加复杂了，似乎不太合理。那就得想一种既能不通过副本又能分散单节点压力就行了，答案就是分片技术，既然单个Leader节点压力太大，那么就分成多个Leader节点，我们只需要一个好的负载均衡算法，通过负载均衡把消息平均分配到各个分片节点就好了，于是我们可以设计出一套大概长这样的生产者-消费者模型。</p>
<p>但是这些只是简单的想法，具体如何实现还是很复杂的，带着这一系列问题和想法，我们来看看kafka是如何实现的。</p>
<h2>思考与实现</h2>
<p>首先我们还是从kafka的几个名词入手，主要介绍下消息、主题、分区和消费者组。
一条消息该怎么设计
消息是服务的源头，一切的设计都是为了将消息从一端送到另一端，这里面涉及到消息的结构，消息体不能太大，太大容易造成存储成本上升，网络传输开销变大，所以消息体只需要包含必要的信息，最好不要冗余。消息最好也支持压缩，通过压缩可以在消息体本身就精简的情况下变的更小，那么存储和网络开销可以进一步降低。消息是要持久化的，被消费掉的消息不能一直存储，或者说非常老的消息被再次消费的可能性不大，需要一套机制来清理老的消息，释放磁盘空间，如何找出老的消息是关键，所以每个消息最好带个消息生产时的时间戳，通过时间戳计算出老的消息，在合适的时候进行删除。消息也是需要编号的，编号一方面代表了消息的位置，另一方面消费者可以通过编号找到对应的消息。大量的消息如何存储也是个问题，全部存储在一个文件中，查询效率低且不利于清理老数据，所以采用分段，通过分段的方式把大的日志文件切割成多个相对小的日志文件来提升维护性，这样当插入消息的时候只要追加在段的最后就行，但是在查找消息的时候如果把整个段加载到内存中一条一条找，似乎也需要很大的内存开销，所以需要一套索引机制，通过索引来加速访问对应的Message。
<img src="https://user-images.githubusercontent.com/22972346/158500312-b49dc866-6f54-4bad-96a7-9eab39c232ea.png" alt="image" /></p>
<p>总结：一条kafka的消息包含创造时间、消息的序号、支持消息压缩，存储消息的日志是分段存储，并且是有索引的。
为什么需要Topic
宏观来看消息引擎就是一发一收，有个问题：生产者A要给消费者B发送消息，同时也要给消费者C发送消息。那么消费者B和消费者C如何只消费到自己需要的数据？能想到的简单的做法就是在消息中加Tag，消费者根据Tag来获取自己的消息，不是自己的消息直接跳过，但是这样似乎不太优雅，而且存在cpu资源浪费在消息的过滤上。所以最有效的办法就是对于给B消息不会给C，给C的消息不会给B，这就是Topic。通过Topic来区分不同的业务，每个消费者只需要订阅自己关注的Topic即可，生产者把消费者需要的消息通过约定好的Topic发过去，那么简单的理解就是消息按照Topic分类了。
<img src="https://user-images.githubusercontent.com/22972346/158500238-0e525cbd-b475-41df-831b-f4526f81ca3e.png" alt="image" /></p>
<p>总结：Topic是个逻辑的概念，Topic可以很好的做业务划分，每个消费者只需要关注自己的Topic即可。
分区如何保证顺序
通过上文我们知道分区的目的就是分散单节点的压力，再结合Topic和Message，那么消息的大概分层就是Topic（主题）-&gt;Partition（分区）-&gt;Message（消息）。也许你会问，既然分区是为了降低单节点的压力，那么干嘛不用多个topic代替多个分区，在多个机器节点的情况下，我们可以把多个topic部署在多个节点上，似乎也能实现分布式，简单一想似乎可行，仔细一想，还是不对。我们最终还要服务业务的，这样的话，本来一个topic的业务，要拆解成多个topic，反而把业务的定义打散了。
好吧，既然有多个分区了，那么消息的分配是个问题，如果topic下面的数据过于集中在某个分区上，又会造成分布不均匀，解决这个问题，一套好的分配算法是很有必要的。
kafka支持轮询法，即在多分区的情况下，通过轮询可以均匀地把消息分给每个分区，这里需要注意的是，每个分区里的数据是有序的，但是整体的数据是无法保证顺序的，如果你的业务强依赖消息的顺序，那么就要慎重考虑这种方案，比如生产者依次发了A、B、C三个消息，它们分别分布在3个分区中，那么有可能出现的消费顺序是B、A、C。</p>
<p>那么如何保证消息的顺序性？从整体的角度来看，只要分区数大于1，就永远无法保证消息的顺序性，除非你把分区数设置成1，但是这样的话吞吐就是问题。从实际的业务场景来说，一般我们可能需要某个用户的消息、或者某个商品的消息有序就可以了，用户A和用户B的消息谁先谁后没关系，因为它们之间没什么关联，但是用户A的消息我们可能要保持有序，比如消息描述的是用户的行为，行为的先后顺序是不能乱的。这时候我们可以考虑用key hash的方式，同一个用户id，通过hash始终能保持分到一个分区上，我们知道分区内部是有序的，所以这样的话，同一个用户的消息一定是有序的，同时不同的用户可以分配到不同的分区上，这样也利用到了多分区的特性。
总结：kafka整体消息是无法保证有序的，但是单个分区的消息是可以保证有序的。
如何设计一个合理的消费者模型
既然是设计消息模型，那么消费者必不可少，实现消费者最简单的方式就是起一个进程或者线程直接去broker里面拉取消息即可，这很合理，但是如果生产的速度大于当前的消费速度怎么办？第一时间想到的就是再起一个消费者，通过多个消费者来提升消费速度，这里似乎又有个问题，两个消费者都消费到了同一条消息怎么办？加锁是个解决方案，但是效率会降低，也许你会说消费的本质就是读，读是可以共享的，只要保证业务幂等，重复消费消息也没关系。这样的话，如果10个消费者都争抢到了同样的消息，结果有9个消费者都是白白浪费资源的。因此在需要多个消费者提升消费能力的同时，还要保证每个消费者都消费到没被处理的消息，这就是消费者组，消费者组下面可以有多个消费者，我们知道topic是分区的，因此只要消费者组内的每个消费者订阅不同的分区就可以了。理想的情况下是每个消费者都分配到相同数据量分区，如果某个消费者获得的分区数不平均（较多或者较少），出现数据倾斜状态，那么就会导致某些消费者非常繁忙或者轻松，这样就不合理，这就需要一套均衡的分配策略。</p>
<p>kafka消费者分区分配策略主要有3种：</p>
<p>Range：这种策略是针对topic的，会把topic的分区数和消费者数进行一个相除，如果有余数，那就说明多余的分区不够平均分了，此时排在前面的消费者会多分得1个分区，乍看其实挺合理，毕竟本来数量就不均衡。但是如果消费者订阅了多个topic，并且每个topic平均算下来都多几个个分区，那么对于排在前面的消费者就会多消费很多分区。</p>
<p>由于是按照topic维度来划分的，所以最终:</p>
<p>c1消费 Topic0-p0、Topic0-p1、Topic1-p0、Topic1-p1
c2消费 Topic0-p2、Topic1-p2</p>
<p>最终可以发现消费者c1比消费者c2整整多两个分区，完全可以把c1的分区分一个给c2，这样就可以均衡了。</p>
<p>RoundRobin：这种策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询算法逐个将分区以此分配给每个消费者。假设现在有两个topic，每个topic3个分区，并且有3个消费者。那么大致消费状况是这样的：</p>
<p>c0消费 Topic0-p0、Topic1-p0
c1消费 Topic0-p1、Topic1-p1
c2消费 Topic0-p2、Topic1-p2</p>
<p>看似很完美，但是如果现在有3个topic，并且每个topic分区数是不一致的，比如topic0只有一个分区，topic1有两个分区，topic2有三个分区，而且消费者c0订阅了topic0，消费者c1订阅了topic0和topic1，消费者c2订阅了topic0、topic1、topic2，那么大致消费状况是这样的：</p>
<p>c0消费 Topic0-p0
c1消费 Topic1-p0
c2消费 Topic1-p1、Topic2-p0、Topic2-p1、Topic2-p2</p>
<p>这么看来RoundRobin并不是最完美的，在不考虑每个topic分区吞吐能力的差异，可以看到c2的消费负担明显很大，完全可以将Topic1-p1分区分给消费者c1。</p>
<p>Sticky：Range和RoundRobin都有各自的缺点，某些情况下可以更加均衡，但是没有做到。</p>
<p>Sticky引入目的之一就是：分区的分配要尽可能均匀。以上面RoundRobin 3个topic分别对应1、2、3个分区的case来说，因为c1完全可以消费Topic1-p1，但是它没有。针对这种情况，在Sticky模式下，就可以做到把Topic1-p1分给c1。</p>
<p>Sticky引入目的之二就是：分区的分配尽可能与上次分配的保持相同。这里主要解决就是rebalance后分区重新分配的问题，假设现在有3个消费者c0、c1、c2，他们都订阅了topic0、topic1、topic2、topic3，并且每个topic都有两个分区，此时消费的状况大概是这样：</p>
<p>这种分配方式目前看RoundRobin没什么区别，但是如果此时消费者c1退出，消费者组内只剩c0、c2。那么就需要把c1的分区重新分给c0和c2，我们先来看看RoundRobin是如何rebalance的：</p>
<p>可以发现原来c0的topic1-p1分给了c2，原来c2的topic1-p0分给了c0。这种情况可能会造成重复消费问题，在消费者还没来得及提交的时候，发现分区已经被分给了一个新的消费者，那么新的消费者就会产生重复消费。但是从理论的角度来说，在c1退出之后，可以没必要去动c0和c2的分区，只需要把原本c1的分区瓜分给c0和c2即可，这就是sticky的做法：
需要注意的是Sticky策略中，如果分区的分配要尽可能均匀和分区的分配尽可能与上次分配的保持相同发生冲突，那么会优先实现第一个。
总结：kafka默认支持以上3种分区分配策略，也支持自定义分区分配，自定义的方式需要自己去实现，从效果来看RoundRobin要好于Range的，Sticky是要好于RoundRobin的，推荐大家使用版本支持的最好的策略。</p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/1" rel="alternate"/><category term="Top"/><published>2022-03-16T01:09:30+00:00</published></entry></feed>