<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom"><id>https://github.com/maminglang/minglang_blog</id><title>RSS feed of maminglang's minglang_blog</title><updated>2022-10-28T07:14:17.579991+00:00</updated><author><name>maminglang</name><email>1622695094@qq.com</email></author><link href="https://github.com/maminglang/minglang_blog"/><link href="https://raw.githubusercontent.com/maminglang/minglang_blog/master/feed.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator><entry><id>https://github.com/maminglang/minglang_blog/issues/19</id><title>多线程基本知识</title><updated>2022-10-28T07:14:17.856196+00:00</updated><content type="html"><![CDATA[<h4>线程状态</h4>
<p>线程状态由Thread.State枚举类来描述，主要有以下几种状态：</p>
<ul>
<li>NEW
此时线程还没还是运行，只是刚创建出来</li>
<li>RUNNABLE</li>
</ul>
<blockquote>
<p>Thread state for a runnable thread.  A thread in the runnable state is executing in the Java virtual machine but it may be waiting for other resources from the operating system such as processor.</p>
</blockquote>
<ul>
<li>BLOCKED</li>
</ul>
<blockquote>
<p>Thread state for a thread blocked waiting for a monitor lock. A thread in the blocked state is waiting for a monitor lock to enter a synchronized block/method or reenter a synchronized block/method after calling {@link Object#wait() Object.wait}</p>
</blockquote>
<ul>
<li>WAITING</li>
</ul>
<blockquote>
<p>/**
* Thread state for a waiting thread.
* A thread is in the waiting state due to calling one of the
* following methods:
* {@link Object#wait() Object.wait} with no timeout
*   {@link #join() Thread.join} with no timeout
*   {@link LockSupport#park() LockSupport.park}
* A thread in the waiting state is waiting for another thread to
* perform a particular action.
*
* For example, a thread that has called <tt>Object.wait()</tt>
* on an object is waiting for another thread to call
* <tt>Object.notify()</tt> or <tt>Object.notifyAll()</tt> on
* that object. A thread that has called <tt>Thread.join()</tt>
* is waiting for a specified thread to terminate.
*/</p>
</blockquote>
<ul>
<li>TIMED_WAITING</li>
</ul>
<blockquote>
<p>/**
* Thread state for a waiting thread with a specified waiting time.
* A thread is in the timed waiting state due to calling one of
* the following methods with a specified positive waiting time:
* <ul>
*   <li>{@link #sleep Thread.sleep}</li>
*   <li>{@link Object#wait(long) Object.wait} with timeout</li>
*   <li>{@link #join(long) Thread.join} with timeout</li>
*   <li>{@link LockSupport#parkNanos LockSupport.parkNanos}</li>
*   <li>{@link LockSupport#parkUntil LockSupport.parkUntil}</li>
* </ul>
*/</p>
</blockquote>
<ul>
<li>TERMINATED</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/19" rel="alternate"/><category term="多线程学习"/><published>2022-10-28T07:12:12+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/18</id><title>RPC学习</title><updated>2022-10-28T07:14:17.975706+00:00</updated><content type="html"><![CDATA[<p>socket，又称<strong>套接字</strong>，是在不同的进程间进行网络通讯的一种协议、约定或者说是规范。
对于socket编程，它更多的时候像是基于<strong>TCP/UDP</strong>等协议做的一层封装或者说抽象，是一套系统所提供的用于进行网络通信相关编程的接口。
java中使用socket编程主要分为客户端和服务器端代码，demo如下：</p>
<pre><code>public class ClientDemo {
    public static void main(String[] args) throws Exception {
        while(true){
            Socket socket = new Socket(&quot;127.0.0.1&quot;, 9999);
            OutputStream os = socket.getOutputStream();
            System.out.println(&quot;请输入：&quot;);
            Scanner scanner = new Scanner(System.in);
            String msg = scanner.nextLine();
            os.write(msg.getBytes());
            InputStream inputStream = socket.getInputStream();
            byte[] bytes = new byte[1024];
            int read = inputStream.read(bytes);
            System.out.println(&quot;老板说：&quot; + new String(bytes,0,read).trim());

        }
    }
}


public class ServerDemo {
    public static void main(String[] args) throws Exception {
        ExecutorService executorService = Executors.newCachedThreadPool();
        ServerSocket serverSocket = new ServerSocket(9999);

        System.out.println(&quot;服务器已经启动&quot;);

        while (true) {
            final Socket socket = serverSocket.accept();
            System.out.println(&quot;有客户端连接&quot;);
            executorService.execute(new Runnable() {
                public void run() {
                    handle(socket);
                }
            });
        }
    }

    private static void handle(Socket socket) {
        try {
            System.out.println(&quot;线程ID: &quot; + Thread.currentThread().getId() + &quot;  线程名称： &quot; + Thread.currentThread().getName());
            InputStream inputStream = socket.getInputStream();
            byte[] bytes = new byte[1024];
            int read = inputStream.read(bytes);
            System.out.println(&quot;客户端输入内容为: &quot; + new String(bytes, 0, read).trim());
            OutputStream outputStream = socket.getOutputStream();
            OutputStream os = socket.getOutputStream();
            System.out.println(&quot;请输入：&quot;);
            Scanner scanner = new Scanner(System.in);
            String msg = scanner.nextLine();
            outputStream.write(msg.getBytes());

        } catch (Exception e) {

        }
    }
}
</code></pre>
<p><img src="https://user-images.githubusercontent.com/22972346/197768649-9fff47bd-220c-4341-8933-d574aa0c92d1.png" alt="image" /></p>
<h2>I/O模型</h2>
<ul>
<li>BIO
同步并阻塞</li>
<li>NIO
同步非阻塞</li>
<li>AIO
异步非阻塞
接下来主要熟悉下Java中的NIO
同步非阻塞，服务器实现模式为一个线程处理多个请求连接，即客户端发送的请求连接都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时候就会进行处理。
<img src="https://user-images.githubusercontent.com/22972346/197769207-18e34ba1-a45d-47b9-b66f-0f6b952d95a4.png" alt="image" /></li>
</ul>
<h3>NIO组件</h3>
<p><img src="https://user-images.githubusercontent.com/22972346/197769396-f6baf1f9-4dca-456f-ade3-59b26225a5df.png" alt="image" /></p>
<ul>
<li>Selector</li>
<li>Channel</li>
<li>
Buffer
<img src="https://user-images.githubusercontent.com/22972346/197769535-44ce624f-09ab-438f-af97-63c6e5dd9e62.png" alt="image" /><ul>
<li>
创建<ul>
<li>使用allocate方法创建指定长度的缓冲区</li>
<li>使用wrap创建指定内容的缓冲区</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/18" rel="alternate"/><published>2022-10-25T12:11:44+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/17</id><title>Java 服务CPU占用高时问题定位方法</title><updated>2022-10-28T07:14:18.088762+00:00</updated><content type="html"><![CDATA[<p>本文提供了一种比较简单的方法来定位CPU高罪魁祸首代码，在CPU占用高的时候，可以通过以下方法，尽快定位相应的代码行</p>
<h1>1.找到占用cpu高的进程</h1>
<p>执行top 命令，找到占用CPU高的进程72471
如下图
<img src="https://user-images.githubusercontent.com/22972346/194806395-fd5796cb-8bf0-4c1c-a00e-c4fa03175aab.png" alt="image" /></p>
<h1>2.执行top -H -p 进程号，找到占用CPU最高的线程号129204，转换成16进制1f8b4</h1>
<p><img src="https://user-images.githubusercontent.com/22972346/194806428-22da948d-e858-46a0-8e26-cf4b6ac33d1c.png" alt="image" /></p>
<h1>3.执行jstack 72471 &gt;72471.log 用来dump出目前代码栈</h1>
<h1>4. 从72471.log 中根据线程号 1f8b4 查找其中的线程相应的代码栈，则可快速定位相应的业务代码</h1>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/17" rel="alternate"/><category term="技术"/><published>2022-10-10T06:02:39+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/16</id><title>SQL 语法简单检查</title><updated>2022-10-28T07:14:18.192153+00:00</updated><content type="html"><![CDATA[<p>最近遇到一个场景。每次版本升级时，要把增量sql放入配置文件里，同时把增量sql的文件内容，同步到全量sql里。这个过程中，如果由于手误等其他各种人为原因，可能导致sql错误，进而导致后期转测存在问题</p>
<p>怎么解决呢，最好的办法在代码review阶段，能够检查出语法错误。</p>
<p>重复造轮子是不现实的。你要检查sql的语法，这个难度相对比较大。这个时候我们发现了<a href="https://github.com/alibaba/druid/wiki/SQL-Parser">Druid MySQL Parser</a></p>
<blockquote>
<p>SQL Parser是Druid的一个重要组成部分，Druid内置使用SQL Parser来实现防御SQL注入（WallFilter）、合并统计没有参数化的SQL(StatFilter的mergeSql)、SQL格式化、分库分表。</p>
</blockquote>
<blockquote>
<p>Druid SQL Parser分三个模块：
Parser parser是将输入文本转换为ast（抽象语法树），parser有包括两个部分，Parser和Lexer，其中Lexer实现词法分析，Parser实现语法分析。
<a href="https://github.com/alibaba/druid/wiki/Druid_SQL_AST">AST</a> AST是Abstract Syntax Tree的缩写，也就是抽象语法树。AST是parser输出的结果
Visitor Visitor是遍历AST的手段，是处理AST最方便的模式</p>
</blockquote>
<p>有了以上功能，我们就可以构建我们自己的sql语法校验模 块了</p>
<p>1.创建一个UT 模块</p>
<p>2.检查sql语法</p>
<p>1.根据文件解析出sql，按分号分割</p>
<pre><code>@Before
public void setUp() throws IOException {
    File f = new File(&quot;123.sql&quot;);
    String allSql = Files.toString(f, Charset.forName(&quot;UTF-8&quot;));
        //根据分号，分割出每一行sql
    sqlList = allSql.split(&quot;;&quot;);
}
</code></pre>
<p>2.根据druid提供的功能校验sql</p>
<pre><code>private List&lt;SqlInfo&gt; getResults(String sql){
    List&lt;SqlInfo&gt; results = new ArrayList&lt;SqlInfo&gt;();
    MySqlStatementParser parser = new MySqlStatementParser(sqls);
    //使用parser 把sql文本转换成AST(抽象语法树)
    List&lt;SQLStatement&gt; stmtList = parser.parseStatementList();
    StringBuilder out = new StringBuilder();
    //使用vistor模式访问AST
    MySqlOutputVisitor visitor = new MySqlOutputVisitor(out);
    for (SQLStatement stmt : stmtList) {
        SqlInfo sqlDto = new SqlInfo();
        stmt.accept(visitor);
        out.append(&quot;;&quot;);
        sqlDto.setSql(out.toString());
        results.add(sqlDto);
    }
    return results;
}
</code></pre>
<p>3.执行test,如果语法校验不通过，会抛出异常</p>
<pre><code>@Test
public void testDataSQL() {
    for (String sql : sqlList) {
        List&lt;SqlInfo&gt; sqlOutput = getResults(sql);
        for (SqlInfo dto : sqlOutput) {
            System.out.println(dto.sql);
        }
    }
}
</code></pre>
<p>编译阶段，自动执行单元测试，就可以有效的减少由人为失误，导致的sql语法问题了</p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/16" rel="alternate"/><category term="技术"/><published>2022-10-10T05:56:36+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/15</id><title>Redis持久化</title><updated>2022-10-28T07:14:18.295834+00:00</updated><content type="html"><![CDATA[<p>Redis持久化主要有两大机制：<strong>AOF</strong>和<strong>RDB</strong></p>
<ul>
<li>
AOF记录的是Redis收到的每一条指令，以文本形式进行保存。<ul>
<li>好处：命令执行完之后才记录日志，所以<strong>不会阻塞当前的写操作</strong></li>
<li>
潜在风险（与AOF写回磁盘的时机相关）：<ul>
<li>
<p>刚执行完命令即宕机，与该命令相关的数据有丢失的风险</p>
</li>
<li>
<p>避免了当前命令的阻塞，有可能给下一个命令带来阻塞。原因是AOF日志也是在主线程中执行的。</p>
</li>
<li>
<p>写回策略（appendsync）</p>
<ul>
<li>Always 同步写回，命令执行完毕立马同步将日志写回磁盘</li>
<li>Everyec 每秒写回，命令执行完先将日志写到AOF文件的内存缓冲区，每隔一秒将缓冲区的内容写入磁盘</li>
<li>No 操作系统控制的写回</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/22972346/194742536-881e1c9f-32c9-4997-a875-ecccc9b6411f.png" alt="image" />
AOF文件过大带来的性能问题：</p>
<ol>
<li>文件系统本身对文件大小有限制</li>
<li>文件过大时候追加记录效率变慢</li>
<li>故障恢复时缓慢影响使用</li>
</ol>
<h3>如何解决日志文件过大？</h3>
<p>AOF重写机制就是在重写时（什么时候进行重写？），Redis根据数据库现状新建一个新的AOF文件，也就是说读取数据库中的所有键值对，然后用每一个键值用一条命令去记录它的写入。将旧日志文件中的多条命令进行合并（最终效果）</p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/15" rel="alternate"/><category term="Redis"/><published>2022-10-10T00:56:18+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/14</id><title>redis学习 day1</title><updated>2022-10-28T07:14:18.403053+00:00</updated><content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/22972346/192457217-11f702fe-76e2-492e-81ee-714beedfdf16.png" alt="redis问题画像" /></p>
<h2>Redis的支持的数据</h2>
<ul>
<li>String</li>
<li>List</li>
<li>hash</li>
<li>Set</li>
<li>Sorted Set
对应的底层数据结构：
<img src="https://user-images.githubusercontent.com/22972346/192484398-fc7b2566-08da-422f-a73f-0a102580aa38.png" alt="数据结构对应" /></li>
</ul>
<h4>redis的数据存储</h4>
<p>为了实现从键到值得快速访问，Redis使用了一个<strong>哈希表</strong>来保存<strong>所有的键值对</strong>
<img src="https://user-images.githubusercontent.com/22972346/192484849-e6a31518-f7d1-4275-b490-c1c37c64a7c7.png" alt="全局哈希表" /></p>
<p>哈希表具有**O(1)**的复杂度和快速查找特性，但是也会遇到问题：</p>
<ol>
<li><strong>哈希表的哈希冲突</strong>
解决方案：哈希冲突链，类比java中hashMap中的哈希冲突解决方案
问题：冲突链过长时候查询退化成<strong>O(n)</strong></li>
<li><strong>rehash可能带来的操作阻塞</strong>
解决方案：使用两个全局哈希表，其中一个在rehash时候进行切换
问题：数据迁移时候会造成Redis线程阻塞。
解决：
渐进式rehash</li>
</ol>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/14" rel="alternate"/><category term="Redis"/><published>2022-09-27T09:06:19+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/13</id><title>服务无法启动-oom问题</title><updated>2022-10-28T07:14:18.508370+00:00</updated><content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/22972346/189820555-f4be6124-bc4e-4c87-a07f-548a5cd8480f.png" alt="7C1B6017-539E-4350-A1DC-0DEE0C7CAF11" />
排查思路：日志中显示启动内存不足</p>
<ul>
<li>登陆服务器，使用<strong>free -m</strong>查看服务器内存使用情况
<img src="https://user-images.githubusercontent.com/22972346/189821679-dfbbc60b-f9ac-4aa3-ab24-77362d8a1a63.png" alt="image" />
然后看下启动脚本中**-Xmx -Xms**的参数配置
<img src="https://user-images.githubusercontent.com/22972346/189821311-676bf12f-6eb6-45c3-a092-b75a9ae6d706.png" alt="image" />
发现是由于配置的堆内存的大小远大于服务器存储剩余存储空间，导致服务无法启动。
将该参数改成笔服务器剩余存储空间较小的值，服务i顺利启动。</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/13" rel="alternate"/><category term="技术"/><published>2022-09-13T06:00:20+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/12</id><title>垃圾收集器</title><updated>2022-10-28T07:14:18.624906+00:00</updated><content type="html"><![CDATA[<h2>对象死亡判断</h2>
<ul>
<li>
<p>引用计数法
给对象设置一个<strong>引用计数器</strong>，每当对象被引用就+1，引用失效-1.
-&gt; 很难解决对象之间循环引用的问题</p>
</li>
<li>
<p>可达性分析算法
基本思路是通过一系列的“GC Roots&quot;对象作为起点，从这些节点开始向下进行搜索，搜索的路径成为<strong>引用链</strong>.当一个对象到GC Roots没有任何引用链时，则该对象不可用。</p>
<ul>
<li>
GC Roots对象
<strong>两栈两方法</strong><ul>
<li>虚拟机栈（本地变量表）中引用的对象</li>
<li>本地方法栈中JNI引用的对象</li>
<li>方法区中静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
</ul>
</li>
<li>
引用的分类<ul>
<li>强引用</li>
<li>软引用
SoftReference类实现软引用。对于软引用关联的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。</li>
<li>弱引用
被弱引用关联的对象只能生存到下一次垃圾收集之前。WeakReference</li>
<li>虚引用
PhantomReference实现虚引用。</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/12" rel="alternate"/><category term="虚拟机"/><published>2022-09-02T01:58:43+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/11</id><title>Java内存区域</title><updated>2022-10-28T07:14:18.736835+00:00</updated><content type="html"><![CDATA[<h2>运行时内存区域</h2>
<ul>
<li>程序计数器
当前线程所执行的字节码的行号指示器。字节码解释器通过程序计数器来选取下一条需要执行的字节码指令。</li>
<li>Java虚拟机栈
<strong>虚拟机栈</strong>描述的时Java方法执行的内存模型：每个方法在执行的时候都会创建一个栈帧，用于存放局部变量表、操作数栈、动态链接和方法出口等信息。</li>
<li>本地方法栈
上述三个属于线程私有的区域</li>
<li>
方法区<ul>
<li>运行时常量池</li>
</ul>
</li>
<li>堆</li>
</ul>
<h2>内寸分配与回收策略</h2>
<ul>
<li>对象优先在Eden分配</li>
<li>大对象直接进入老年代</li>
<li>长期存活的对象进入老年代
虚拟机采用分代的思想管理内存，那么内存回收的时候就必须能够识别哪些对象应该放在新生代，哪些对象应该放在老年代中。为了实现这点，虚拟机给每个对象设置<strong>年龄计数器</strong>。</li>
<li>对象的动态年龄判定
除了年龄计数器值卡，如果在Survivor空间中相同年龄所以对象的总和大于Survivor空间的一般，年龄大于等于该年龄的对象直接进入老年代，无需等到MaxTenuringThreshold中要求的年龄。</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/11" rel="alternate"/><category term="虚拟机"/><published>2022-08-31T01:35:49+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/10</id><title>配置文件热加载</title><updated>2022-10-28T07:14:18.846650+00:00</updated><content type="html"><![CDATA[<ul>
<li>
<p><strong>怎么实现配置文件的热加载</strong>？
java1.7中 提供了WatchService来监控系统中文件的变化。该监控是基于操作系统的文件系统监控器，可以监控系统是所有文件的变化，这种监控是无需遍历、无需比较的，是一种基于信号收发的监控，因此效率一定是最高的；现在Java对其进行了包装，可以直接在Java程序中使用OS的文件系统监控器了。</p>
</li>
<li>
<p><strong>使用场景</strong>
场景一：比如系统中的配置文件，一般都是系统启动的时候只加载一次，如果想修改配置文件，还须重启系统。如果系统想热加载一般都会定时轮询对比配置文件是否修改过，如果修改过重新加载。
场景二：监控磁盘中的文件变化，一般需要把磁盘中的所有文件全部加载一边，定期轮询一遍磁盘，跟上次的文件状态对比。如果文件、目录过多，每次遍历时间都很长，而且还不是实时监控。</p>
</li>
<li>
<p><strong>实现思路</strong>
监控文件修改及创建事件</p>
</li>
</ul>
<pre><code>import java.io.File;
import java.io.IOException;
import java.net.URI;
import java.net.URISyntaxException;
import java.nio.file.FileSystems;
import java.nio.file.Path;
import java.nio.file.StandardWatchEventKinds;
import java.nio.file.WatchEvent;
import java.nio.file.WatchKey;
import java.nio.file.WatchService;
import java.util.Arrays;
import java.util.HashSet;
import java.util.Map;
import java.util.Objects;
import java.util.Set;
import java.util.function.Consumer;

import javax.annotation.PostConstruct;

import org.springframework.context.annotation.Configuration;
import org.springframework.scheduling.annotation.EnableScheduling;
import org.springframework.scheduling.annotation.Scheduled;

import com.google.common.collect.Maps;

import lombok.extern.slf4j.Slf4j;

/**
 * 自动热加载配置类
 *
 * @author c00566803
 * @since 2022-08-15
 */
@Configuration
@EnableScheduling
@Slf4j
public class AutoReloadConfiguration {
    /**
     * 文件监测时间间隔，默认1分钟
     */
    public static final long WATCH_INTERVAL = 60 * 1000;

    private static final String PREFIX_FILE = &quot;.&quot;;

    private WatchService watchService;

    private Map&lt;String, Consumer&lt;WatchEvent.Kind&lt;Path&gt;&gt;&gt; consumers = Maps.newHashMap();

    /**
     * 初始化方法
     */
    @PostConstruct
    public void init() {
        try {
            watchService = FileSystems.getDefault().newWatchService();

            // 默认监控classpath下面所有文件和子目录的变化
            URI uri = AutoReloadConfiguration.class.getResource(&quot;/&quot;).toURI();
            File baseDir = new File(uri);
            File[] childDirs = baseDir.listFiles(File::isDirectory);
            Set&lt;File&gt; watchedDirs = new HashSet&lt;&gt;();
            watchedDirs.add(baseDir);
            if (Objects.nonNull(childDirs)) {
                Arrays.asList(childDirs).forEach(file -&gt; watchedDirs.add(file));
            }
            for (File dir : watchedDirs) {
                Path path = dir.toPath();
                log.info(&quot;watch path {}&quot;, path);

                // 监控文件修改及创建事件
                path.register(watchService, StandardWatchEventKinds.ENTRY_MODIFY, StandardWatchEventKinds.ENTRY_CREATE);
            }
        } catch (IOException | URISyntaxException e) {
            log.error(&quot;error while register watch service&quot;);
        }
    }

    /**
     * 注册监听文件
     *
     * @param filePath 文件全路径
     * @param consumer 回调事件
     */
    public void register(String filePath, Consumer&lt;WatchEvent.Kind&lt;Path&gt;&gt; consumer) {
        log.info(&quot;register watch service of {}&quot;, filePath);
        if (Objects.isNull(filePath)) {
            log.warn(&quot;{} is not regular file&quot;, filePath);
        } else {
            consumers.put(filePath, consumer);
            consumers.put(PREFIX_FILE + filePath, consumer);
        }
    }

    /**
     * 定时任务
     */
    @Scheduled(fixedRate = WATCH_INTERVAL)
    public void watch() {
        WatchKey key = watchService.poll();
        if (Objects.nonNull(key)) {
            Map&lt;String, WatchEvent.Kind&lt;Path&gt;&gt; changedFiles = getChangedFiles(key);

            // 处理所有文件变化的事件
            changedFiles.forEach((s, kind) -&gt; {
                if (consumers.containsKey(s)) {
                    log.info(&quot;reload file {}&quot;, s);
                    consumers.get(s).accept(kind);
                }
            });

            // 此处必须reset，不然后续事件无法获取
            key.reset();
        }
    }

    private Map&lt;String, WatchEvent.Kind&lt;Path&gt;&gt; getChangedFiles(WatchKey key) {
        Map&lt;String, WatchEvent.Kind&lt;Path&gt;&gt; changedFiles = Maps.newHashMap();

        // 获取所有变化的文件，一个文件多次变化默认取最后一个事件
        for (WatchEvent&lt;?&gt; event : key.pollEvents()) {
            log.info(&quot;Event kind: {}. File affected: {}.&quot;, event.kind(), event.context());
            if (event.context() instanceof Path) {
                Path path = (Path) event.context();
                Path fileName = path.getFileName();
                if (Objects.isNull(fileName)) {
                    log.warn(&quot;{} is not regular file&quot;, path);
                } else {
                    changedFiles.put(fileName.toString(), getKind(event));
                    log.info(&quot;fileName: {}.&quot;, fileName);
                }
            }
        }
        return changedFiles;
    }

    @SuppressWarnings({&quot;unchecked&quot;})
    private WatchEvent.Kind&lt;Path&gt; getKind(WatchEvent&lt;?&gt; event) {
        return (WatchEvent.Kind&lt;Path&gt;) event.kind();
    }
}
</code></pre>
<p>配置类：</p>
<pre><code>import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.nio.file.Path;
import java.nio.file.WatchEvent;
import java.util.Properties;
import java.util.function.Consumer;

import javax.annotation.PostConstruct;

import org.springframework.beans.BeanUtils;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import com.alibaba.fastjson.JSON;
import com.alibaba.fastjson.JSONObject;

import lombok.extern.slf4j.Slf4j;

/**
 * 热加载相关配置
 *
 * @author c00566803
 * @since 2022-08-15
 */
@Slf4j
@Component
public class HotLoadConfiguration {
    private String configFile = &quot;visualization.properties&quot;;

    @Autowired
    private HotLoadProperties hotLoadProperties;

    @Autowired
    private AutoReloadConfiguration autoReloadConfiguration;

    /**
     * 初始化函数
     *
     * @throws IOException IO异常
     */
    @PostConstruct
    public void init() {
        try {
            reloadConfig();
        } catch (IOException e) {
            log.error(&quot;配置文件加载异常&quot;);
        }
        register();
    }


    //加载配置文件
    private void reloadConfig() throws IOException {
        Properties properties = new Properties();
        try (InputStream resource = ClassLoader.getSystemResourceAsStream(configFile)) {
            InputStreamReader inputStreamReader = new InputStreamReader(resource, &quot;UTF-8&quot;);
            properties.load(inputStreamReader);
            String config = JSON.toJSONString(properties);
            log.info(&quot;before hotLoadProperties = &quot; + hotLoadProperties);
            HotLoadProperties configSource = JSONObject.parseObject(config, HotLoadProperties.class);
            BeanUtils.copyProperties(configSource, hotLoadProperties);
            inputStreamReader.close();
            log.info(&quot;after hotLoadProperties = &quot; + hotLoadProperties);
            log.info(&quot;success read config : {}&quot;, configFile);
        }
    }

    private void register() {
        Consumer&lt;WatchEvent.Kind&lt;Path&gt;&gt; consumer = kind -&gt; {
            try {
                reloadConfig();
            } catch (IOException e) {
                log.error(&quot;reload failed&quot;, e);
            }
        };

        // visualization.properties配置文件
        autoReloadConfiguration.register(configFile, consumer);
    }
}

</code></pre>
<pre><code>import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.PropertySource;
import org.springframework.stereotype.Component;

import com.alibaba.fastjson.annotation.JSONField;

import lombok.Getter;
import lombok.Setter;
import lombok.ToString;

/**
 * HotLoadProperties 热加载属性
 *
 * @author c00566803
 * @since 2022-08-15
 */
@Configuration
@PropertySource(&quot;classpath:visualization.properties&quot;)
@Component
@Getter
@Setter
@ToString
public class HotLoadProperties {
    @Value(&quot;${task.hag.server}&quot;)
    @JSONField(name = &quot;task.hag.server&quot;)
    private String hagServer;
}

</code></pre>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/10" rel="alternate"/><category term="技术"/><published>2022-08-17T07:40:30+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/9</id><title>记SpringBoot从2.5.8升级到2.6.7遇到的循环依赖问题</title><updated>2022-10-28T07:14:18.957582+00:00</updated><content type="html"><![CDATA[<p>在SpringBoot升级完成之后，项目启动遇到问题，报了这么一个错误：
<img src="https://user-images.githubusercontent.com/22972346/171575651-1280e4f6-6317-41c3-8703-9816f7f7a0db.png" alt="image" /></p>
<blockquote>
<p>Action:
Relying upon circular references is discouraged and they are prohibited by default. Update your application to remove the &gt; dependency cycle between beans. As a last resort, it may be possible to break the cycle automatically by setting &gt; spring.main.allow-circular-references to true</p>
</blockquote>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/9" rel="alternate"/><category term="技术"/><published>2022-06-02T07:08:35+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/8</id><title>Head和Body相关</title><updated>2022-10-28T07:14:19.069331+00:00</updated><content type="html"><![CDATA[<h2>HTTP的实体数据</h2>
<p>####数据类型使用的头字段</p>
<ul>
<li><strong>Accept/Accept-Encoding</strong></li>
<li><strong>Content-Type/Content-Encoding</strong></li>
</ul>
<h4>语言类型与字符集</h4>
<ul>
<li><strong>Accept-Language/Accept-Charset</strong>字段标记了客户端可理解的自然语言与字符集</li>
<li>服务器应该在响应报文里用头字段<strong>Content-Language</strong>告诉客户端实体数据使用的实际语言类型。响应头里却没有对应的Content-Charset，而是在Content-Type字段的数据类型后面用“charset=xxx”来表示，这点需要特别注意</li>
</ul>
<pre><code class="language-java">Accept-Charset: gbk, utf-8
Content-Type: text/html; charset=utf-8
</code></pre>
<h2>HTTP大文件传输</h2>
<ul>
<li>压缩</li>
<li>分块传输
使用&quot;chunked&quot;分块传输编码，在响应头中用头字段**&quot;Transfer-Encoding:chunked&quot;**表示</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/8" rel="alternate"/><category term="HTTP相关"/><published>2022-05-27T01:10:20+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/7</id><title>相应状态码</title><updated>2022-10-28T07:14:19.183328+00:00</updated><content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/22972346/170392132-39e0193a-d7a2-4b67-b515-2eae48bf658b.png" alt="image" /></p>
<ul>
<li>1××：提示信息，表示目前是协议处理的中间状态，还需要后续的操作；</li>
<li>2××：成功，报文已经收到并被正确处理；
<strong>200 OK</strong>
<strong>204 Not Content</strong>：与200基本相同，但是响应头后没有body数据
<strong>206 Partial Content</strong>：服务器成功处理请求，但是body中的数据不是全部资源，二十其中的一部分，是HTTP分块下载或断点续传的基础。通常会伴随头部字段“Content-Range”，表示相应报文中body数据的具体范围。例如“Content-Range: bytes 0-99/2000”，意思是此次获取的是总计2000个字节的前100个字节</li>
<li>3××：重定向，资源位置发生变动，需要客户端重新发送请求；
**“301 Moved Permanently”**俗称“永久重定向”，含义是此次请求的资源已经不存在
了，需要改用新的URI再次访问。</li>
</ul>
<p>与它类似的是“302 Found”，曾经的描述短语是“Moved Temporarily”，俗称“临时重定向”，意思是请求的资源还在，但需要暂时用另一个URI来访问。</p>
<ul>
<li>
<p>4××：客户端错误，请求报文有误，服务器无法处理；
**“400 Bad Request”**是一个通用的错误码，表示请求报文有错误，但具体是数据格式错误、缺少请求头还是URI超长它没有明确说，只是一个笼统的错误，客户端看到400只会是“一头雾水”“不知所措”。所以，在开发Web应用时应当尽量避免给客户端返回400，而是要用其他更有明确含义的状态码。</p>
<p>**“403 Forbidden”**实际上不是客户端的请求出错，而是表示服务器禁止访问资
源。原因可能多种多样，例如信息敏感、法律禁止等，如果服务器友好一点，可以
在body里详细说明拒绝请求的原因，不过现实中通常都是直接给一个“闭门羹”。</p>
</li>
</ul>
<p>**“404 Not Found”**可能是我们最常看见也是最不愿意看到的一个状态码，它的原意是资源在本服务器上未找到，所以无法提供给客户端</p>
<ul>
<li>5××：服务器错误，服务器在处理请求时内部发生了错误
**“500 Internal Server Error”**与400类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析。</li>
</ul>
<p>**“501 Not Implemented”**表示客户端请求的功能还不支持，这个错误码比500要“温和”一些，和“即将开业，敬请期待”的意思差不多，不过具体什么时候“开业”就不好说了。</p>
<p>**“502 Bad Gateway”**通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的。</p>
<p>**“503 Service Unavailable”**表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码503。</p>
<p>503是一个“临时”的状态，很可能过几秒钟后服务器就不那么忙了，可以继续提供服务，所以503响应报文里通常还会有一个“Retry-After”字段，指示客户端可以在多久以后再次尝试发送请求。</p>
<h2>HTTP协议的特点</h2>
<ul>
<li>1.HTTP是灵活可扩展的，可以任意添加头字段实现任意功能；</li>
<li>2.HTTP是可靠传输协议，基于TCP/IP协议“尽量”保证数据的送达；</li>
<li>3.HTTP是应用层协议，比FTP、SSH等更通用功能更多，能够传输任意数据；</li>
<li>4.HTTP使用了请求-应答模式，客户端主动发起请求，服务器被动回复请求；</li>
<li>5.HTTP本质上是无状态的，每个请求都是互相独立、毫无关联的，协议不要求客户端或服务器记录请求相关的信息。</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/7" rel="alternate"/><category term="HTTP相关"/><published>2022-05-26T00:50:32+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/6</id><title>请求方法</title><updated>2022-10-28T07:14:19.292998+00:00</updated><content type="html"><![CDATA[<h2>标准请求方法</h2>
<p>目前HTTP/1.1规定了八种方法：</p>
<ul>
<li><strong>GET</strong>   获取数据</li>
<li><strong>HEAD</strong> 获取资源的元数据</li>
<li><strong>POST</strong>  像资源提交数据，相当于上传或写入</li>
<li><strong>PUT</strong>  类post</li>
<li>DELETE</li>
<li>CONNECT 建立特殊的连接隧道</li>
<li>OPTIONS 列出可对资源实行的方法</li>
<li>TRACE 最总请求-相应的传输路径</li>
</ul>
<h2>安全和幂等</h2>
<p>安全：在HTTP协议中，<strong>安全</strong>是指请求方法不会破坏服务器上的资源，即不会对服务器上的资源造成实质的修改
幂等：多次执行相同的操作，姐夫哦也都是相同的。</p>
<h2>URI格式</h2>
<p><img src="https://user-images.githubusercontent.com/22972346/170390312-0d76f62d-9702-43d4-b864-837d06961120.png" alt="image" /></p>
<ul>
<li><strong>schema</strong>:协议名，规定资源应该使用哪种协议来访问</li>
<li>://之后是**“authority”<strong>部分，表示</strong>资源所在的主机名**，通常采用‘’host:port&quot;的形式。HTTP默认端口号为80，HTTPS默认端口号为443</li>
<li>标记资源所在位置的path
<img src="https://user-images.githubusercontent.com/22972346/170391320-d4f8abe7-e655-4dce-a0d0-93fb4ec4fc65.png" alt="image" /></li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/6" rel="alternate"/><category term="HTTP相关"/><published>2022-05-25T09:49:21+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/5</id><title>并发基础</title><updated>2022-10-28T07:14:19.405873+00:00</updated><content type="html"><![CDATA[<ul>
<li>并发变成Bug源头</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/5" rel="alternate"/><category term="多线程学习"/><published>2022-05-19T08:35:48+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/2</id><title>HTTP专栏学习</title><updated>2022-10-28T07:14:19.518377+00:00</updated><content type="html"><![CDATA[<h3>名词解释</h3>
<ul>
<li>CND
Content Delivery Network，内容分发网络，工作在客户端和服务器之间，它应用了HTTP协议里的缓存和代理技术，代替源站响应客户端的请求，主要起到缓存加速的作用。</li>
<li>URI
Uniform Resource Identifier，统一资源标识符。其组成部分为：
<code>http://nginx.org/en/download.html</code>
1.协议名
2.主机名
3.路径</li>
<li>代理 Proxy
是HTTP协议中请求方和应答方中间的一个环节。代理种类一般分为：
1.匿名代理
2.透明代理
3.正向代理
4.反向代理，代表服务器相应客户端请求</li>
</ul>
<h3>什么是http?</h3>
<p>HTTP就是<strong>超文本传输协议</strong>，也就是<strong>HyperText Transfer Protocol</strong>
通俗一点的解释是：HTTP是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范</p>
<blockquote>
<p>Q:有一种流行的说法：“<strong>HTTP是用于从互联网服务器传输超文本到本地浏览器的协议</strong>”，你认为这种说法对吗？对在哪里，又错在哪里？</p>
</blockquote>
<blockquote>
<p>A:这种说法是不对的。HTTP是互联网中两点之间传输超文本的协议，这两点指的是浏览器-服务器，服务器-服务器和服务器到浏览器，浏览器-浏览器之间是不能用http协议的。且两点之间可以有其他的“中转”。除此之外，http不是协议栈，它是运行在TCP/IP协议上栈上的协议.
Q:DNS(domain name system)和URI的关系是什么</p>
</blockquote>
<blockquote>
<p>A:DNS与URI的的关系： URI用来标记互联网资源的名字，方便以后通过这个名字进行访问。它的实现有URL和URN，其中URL规定了访问资源的方式。 在我们利用URL获取资源的时候，如果采用的是主机名的方式则需要对应的转化为IP地址（真实的传输过程中还是采用ip地址进行寻址），这个转换的过程就是DNS域名解析</p>
</blockquote>
<p><img src="https://user-images.githubusercontent.com/22972346/164650195-7d4363f7-d4af-478e-9b4e-eb65fa2c4b82.png" alt="image" /></p>
<ul>
<li>请求行
请求行描述的<strong>客户端想要如何操作服务器端的资源</strong>，主要由一下三个部分构成：</li>
</ul>
<ol>
<li>请求方法：GET/POST，表示对资源的操作</li>
<li>请求目标： 通常是一个URI，用于标记请求方法想要操作的资源</li>
<li>版本号：表示报文使用的HTTP协议版本
<img src="https://user-images.githubusercontent.com/22972346/170173361-b602ffa9-2dd4-4b4f-acb5-31b9bb2e982e.png" alt="image" /></li>
</ol>
<p>与<strong>请求行</strong>对应的是相应报文中的<strong>状态行</strong>，意思是<strong>服务器状态的相应</strong>
<img src="https://user-images.githubusercontent.com/22972346/170173534-2c43d6e2-b954-48e9-aea0-8a4e119a48b4.png" alt="image" />
如图所示，状态行也分为三个部分：
1.版本号
2.状态码：一个三位数字，用代码的形式表示处理的结果
3.原因：数字状态码的补充</p>
<ul>
<li><strong>头部字段</strong>
HTTP协议主要分为一下四大类：
1.通用字段
2.请求字段
3.相应字段
4.实体字段</li>
<li>常用字段
<strong>Host</strong>:请求字段，该字段告诉服务器这个请求应该由哪个主机来处理
<strong>User-Agent</strong>：请求字段，使用一个字符串来描述发起HTTP请求得客户端
<strong>Date</strong>：通用字段，通常出现在相应头中，表示HTTP报文创建的时间，客户端据此
再搭配其他字段决定缓存策略。
<strong>Server</strong>：相应字段，告诉客户端当前正在提供Web服务的软件名称和版本号。</li>
</ul>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/2" rel="alternate"/><category term="HTTP相关"/><published>2022-04-20T05:56:04+00:00</published></entry><entry><id>https://github.com/maminglang/minglang_blog/issues/1</id><title>消息队列Kafka学习</title><updated>2022-10-28T07:14:19.636295+00:00</updated><content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/22972346/158500100-08edc531-01b9-4060-ab93-87c7d4cc7b7a.png" alt="image" /></p>
<p>这整个下单过程，如果全部同步阻塞，那么耗时会增加，用户等待的时间会加长，体验不太好，同时下单过程依赖的链路越长，风险越大。为了加快响应，减少风险，我们可以把一些非必须卡在主链路中的业务拆解出去，让它们和主业务解耦。下单的最关键核心就是要保证库存、用户支付、商家打款的一致性，消息的通知完全可以走异步。这样整个下单过程不会因为通知商家或者通知用户阻塞而阻塞，也不会因为它们失败而提示订单失败。</p>
<p><img src="https://user-images.githubusercontent.com/22972346/158500145-04bfeb6c-b27f-4688-b465-abe0a8229631.png" alt="image" /></p>
<p>接下来就是如何设计一个消息引擎了，宏观来看一个消息引擎支持发送、存储、接收就行了。
<img src="https://user-images.githubusercontent.com/22972346/158500157-b88a75cc-8057-467d-a44d-c8935359acdc.png" alt="image" /></p>
<p>那么如上图一个简易消息队列模型出现了，Engine把发送方的消息存储起来，这样当接收方来找Engine要数据的时候，Engine再从存储中把数据响应给接收放就ok了。既然涉及到持久化的存储，那么缓慢的磁盘IO是要考虑的问题。还有接收方可能不止一个，以上述订单为例，下单完成之后，通过消息把完成事件发出去，这时候负责用户侧推送的开发需要消费这条消息，负责商户侧推送的开发也需要消费这条消息，能想到的最简单的做法就是copy出两套消息，但是这样是不是显得有点浪费？高可用也是一个需要考虑的点，那么我们的engine是不是得副本，有了副本之后，如果一个engine节点挂掉，我们可以选举出一个新副本来工作。光有副本也不行，发送方可能也是多个，这时候如果所有的发送方都把数据打到一个Leader（主）节点上似乎也不合理，单个节点的压力太大。可能你会说：不是有副本吗？让接收方直接从副本读取消息。这样的话又带来另一个问题：副本复制Leader的消息延迟了咋办？读不到消息再读一次Leader？如果这样的话，引擎的设计的貌似更加复杂了，似乎不太合理。那就得想一种既能不通过副本又能分散单节点压力就行了，答案就是分片技术，既然单个Leader节点压力太大，那么就分成多个Leader节点，我们只需要一个好的负载均衡算法，通过负载均衡把消息平均分配到各个分片节点就好了，于是我们可以设计出一套大概长这样的生产者-消费者模型。</p>
<p>但是这些只是简单的想法，具体如何实现还是很复杂的，带着这一系列问题和想法，我们来看看kafka是如何实现的。</p>
<h2>思考与实现</h2>
<p>首先我们还是从kafka的几个名词入手，主要介绍下消息、主题、分区和消费者组。
一条消息该怎么设计
消息是服务的源头，一切的设计都是为了将消息从一端送到另一端，这里面涉及到消息的结构，消息体不能太大，太大容易造成存储成本上升，网络传输开销变大，所以消息体只需要包含必要的信息，最好不要冗余。消息最好也支持压缩，通过压缩可以在消息体本身就精简的情况下变的更小，那么存储和网络开销可以进一步降低。消息是要持久化的，被消费掉的消息不能一直存储，或者说非常老的消息被再次消费的可能性不大，需要一套机制来清理老的消息，释放磁盘空间，如何找出老的消息是关键，所以每个消息最好带个消息生产时的时间戳，通过时间戳计算出老的消息，在合适的时候进行删除。消息也是需要编号的，编号一方面代表了消息的位置，另一方面消费者可以通过编号找到对应的消息。大量的消息如何存储也是个问题，全部存储在一个文件中，查询效率低且不利于清理老数据，所以采用分段，通过分段的方式把大的日志文件切割成多个相对小的日志文件来提升维护性，这样当插入消息的时候只要追加在段的最后就行，但是在查找消息的时候如果把整个段加载到内存中一条一条找，似乎也需要很大的内存开销，所以需要一套索引机制，通过索引来加速访问对应的Message。
<img src="https://user-images.githubusercontent.com/22972346/158500312-b49dc866-6f54-4bad-96a7-9eab39c232ea.png" alt="image" /></p>
<p>总结：一条kafka的消息包含创造时间、消息的序号、支持消息压缩，存储消息的日志是分段存储，并且是有索引的。
为什么需要Topic
宏观来看消息引擎就是一发一收，有个问题：生产者A要给消费者B发送消息，同时也要给消费者C发送消息。那么消费者B和消费者C如何只消费到自己需要的数据？能想到的简单的做法就是在消息中加Tag，消费者根据Tag来获取自己的消息，不是自己的消息直接跳过，但是这样似乎不太优雅，而且存在cpu资源浪费在消息的过滤上。所以最有效的办法就是对于给B消息不会给C，给C的消息不会给B，这就是Topic。通过Topic来区分不同的业务，每个消费者只需要订阅自己关注的Topic即可，生产者把消费者需要的消息通过约定好的Topic发过去，那么简单的理解就是消息按照Topic分类了。
<img src="https://user-images.githubusercontent.com/22972346/158500238-0e525cbd-b475-41df-831b-f4526f81ca3e.png" alt="image" /></p>
<p>总结：Topic是个逻辑的概念，Topic可以很好的做业务划分，每个消费者只需要关注自己的Topic即可。
分区如何保证顺序
通过上文我们知道分区的目的就是分散单节点的压力，再结合Topic和Message，那么消息的大概分层就是Topic（主题）-&gt;Partition（分区）-&gt;Message（消息）。也许你会问，既然分区是为了降低单节点的压力，那么干嘛不用多个topic代替多个分区，在多个机器节点的情况下，我们可以把多个topic部署在多个节点上，似乎也能实现分布式，简单一想似乎可行，仔细一想，还是不对。我们最终还要服务业务的，这样的话，本来一个topic的业务，要拆解成多个topic，反而把业务的定义打散了。
好吧，既然有多个分区了，那么消息的分配是个问题，如果topic下面的数据过于集中在某个分区上，又会造成分布不均匀，解决这个问题，一套好的分配算法是很有必要的。
kafka支持轮询法，即在多分区的情况下，通过轮询可以均匀地把消息分给每个分区，这里需要注意的是，每个分区里的数据是有序的，但是整体的数据是无法保证顺序的，如果你的业务强依赖消息的顺序，那么就要慎重考虑这种方案，比如生产者依次发了A、B、C三个消息，它们分别分布在3个分区中，那么有可能出现的消费顺序是B、A、C。</p>
<p>那么如何保证消息的顺序性？从整体的角度来看，只要分区数大于1，就永远无法保证消息的顺序性，除非你把分区数设置成1，但是这样的话吞吐就是问题。从实际的业务场景来说，一般我们可能需要某个用户的消息、或者某个商品的消息有序就可以了，用户A和用户B的消息谁先谁后没关系，因为它们之间没什么关联，但是用户A的消息我们可能要保持有序，比如消息描述的是用户的行为，行为的先后顺序是不能乱的。这时候我们可以考虑用key hash的方式，同一个用户id，通过hash始终能保持分到一个分区上，我们知道分区内部是有序的，所以这样的话，同一个用户的消息一定是有序的，同时不同的用户可以分配到不同的分区上，这样也利用到了多分区的特性。
总结：kafka整体消息是无法保证有序的，但是单个分区的消息是可以保证有序的。
如何设计一个合理的消费者模型
既然是设计消息模型，那么消费者必不可少，实现消费者最简单的方式就是起一个进程或者线程直接去broker里面拉取消息即可，这很合理，但是如果生产的速度大于当前的消费速度怎么办？第一时间想到的就是再起一个消费者，通过多个消费者来提升消费速度，这里似乎又有个问题，两个消费者都消费到了同一条消息怎么办？加锁是个解决方案，但是效率会降低，也许你会说消费的本质就是读，读是可以共享的，只要保证业务幂等，重复消费消息也没关系。这样的话，如果10个消费者都争抢到了同样的消息，结果有9个消费者都是白白浪费资源的。因此在需要多个消费者提升消费能力的同时，还要保证每个消费者都消费到没被处理的消息，这就是消费者组，消费者组下面可以有多个消费者，我们知道topic是分区的，因此只要消费者组内的每个消费者订阅不同的分区就可以了。理想的情况下是每个消费者都分配到相同数据量分区，如果某个消费者获得的分区数不平均（较多或者较少），出现数据倾斜状态，那么就会导致某些消费者非常繁忙或者轻松，这样就不合理，这就需要一套均衡的分配策略。</p>
<p>kafka消费者分区分配策略主要有3种：</p>
<p>Range：这种策略是针对topic的，会把topic的分区数和消费者数进行一个相除，如果有余数，那就说明多余的分区不够平均分了，此时排在前面的消费者会多分得1个分区，乍看其实挺合理，毕竟本来数量就不均衡。但是如果消费者订阅了多个topic，并且每个topic平均算下来都多几个个分区，那么对于排在前面的消费者就会多消费很多分区。</p>
<p>由于是按照topic维度来划分的，所以最终:</p>
<p>c1消费 Topic0-p0、Topic0-p1、Topic1-p0、Topic1-p1
c2消费 Topic0-p2、Topic1-p2</p>
<p>最终可以发现消费者c1比消费者c2整整多两个分区，完全可以把c1的分区分一个给c2，这样就可以均衡了。</p>
<p>RoundRobin：这种策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询算法逐个将分区以此分配给每个消费者。假设现在有两个topic，每个topic3个分区，并且有3个消费者。那么大致消费状况是这样的：</p>
<p>c0消费 Topic0-p0、Topic1-p0
c1消费 Topic0-p1、Topic1-p1
c2消费 Topic0-p2、Topic1-p2</p>
<p>看似很完美，但是如果现在有3个topic，并且每个topic分区数是不一致的，比如topic0只有一个分区，topic1有两个分区，topic2有三个分区，而且消费者c0订阅了topic0，消费者c1订阅了topic0和topic1，消费者c2订阅了topic0、topic1、topic2，那么大致消费状况是这样的：</p>
<p>c0消费 Topic0-p0
c1消费 Topic1-p0
c2消费 Topic1-p1、Topic2-p0、Topic2-p1、Topic2-p2</p>
<p>这么看来RoundRobin并不是最完美的，在不考虑每个topic分区吞吐能力的差异，可以看到c2的消费负担明显很大，完全可以将Topic1-p1分区分给消费者c1。</p>
<p>Sticky：Range和RoundRobin都有各自的缺点，某些情况下可以更加均衡，但是没有做到。</p>
<p>Sticky引入目的之一就是：分区的分配要尽可能均匀。以上面RoundRobin 3个topic分别对应1、2、3个分区的case来说，因为c1完全可以消费Topic1-p1，但是它没有。针对这种情况，在Sticky模式下，就可以做到把Topic1-p1分给c1。</p>
<p>Sticky引入目的之二就是：分区的分配尽可能与上次分配的保持相同。这里主要解决就是rebalance后分区重新分配的问题，假设现在有3个消费者c0、c1、c2，他们都订阅了topic0、topic1、topic2、topic3，并且每个topic都有两个分区，此时消费的状况大概是这样：</p>
<p>这种分配方式目前看RoundRobin没什么区别，但是如果此时消费者c1退出，消费者组内只剩c0、c2。那么就需要把c1的分区重新分给c0和c2，我们先来看看RoundRobin是如何rebalance的：</p>
<p>可以发现原来c0的topic1-p1分给了c2，原来c2的topic1-p0分给了c0。这种情况可能会造成重复消费问题，在消费者还没来得及提交的时候，发现分区已经被分给了一个新的消费者，那么新的消费者就会产生重复消费。但是从理论的角度来说，在c1退出之后，可以没必要去动c0和c2的分区，只需要把原本c1的分区瓜分给c0和c2即可，这就是sticky的做法：
需要注意的是Sticky策略中，如果分区的分配要尽可能均匀和分区的分配尽可能与上次分配的保持相同发生冲突，那么会优先实现第一个。
总结：kafka默认支持以上3种分区分配策略，也支持自定义分区分配，自定义的方式需要自己去实现，从效果来看RoundRobin要好于Range的，Sticky是要好于RoundRobin的，推荐大家使用版本支持的最好的策略。</p>
]]></content><link href="https://github.com/maminglang/minglang_blog/issues/1" rel="alternate"/><category term="Top"/><published>2022-03-16T01:09:30+00:00</published></entry></feed>